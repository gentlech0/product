{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ライブラリのインポート\nimport numpy as np\nimport pandas as pd\nimport os\n\n# データフレーム読み込み\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\n\n# データ結合\nall_df = pd.concat([train_df,test_df],axis=0,ignore_index=True)\nmax_row = len(all_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:23.040030Z","iopub.execute_input":"2025-08-18T13:47:23.040336Z","iopub.status.idle":"2025-08-18T13:47:28.545410Z","shell.execute_reply.started":"2025-08-18T13:47:23.040307Z","shell.execute_reply":"2025-08-18T13:47:28.544458Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# all_df.info() # 特徴量、欠損、型確認","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T04:05:32.136041Z","iopub.execute_input":"2025-08-16T04:05:32.136413Z","iopub.status.idle":"2025-08-16T04:05:32.643085Z","shell.execute_reply.started":"2025-08-16T04:05:32.136355Z","shell.execute_reply":"2025-08-16T04:05:32.642114Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T03:01:12.573520Z","iopub.execute_input":"2025-08-16T03:01:12.573762Z","iopub.status.idle":"2025-08-16T03:01:12.600181Z","shell.execute_reply.started":"2025-08-16T03:01:12.573744Z","shell.execute_reply":"2025-08-16T03:01:12.599000Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 数値列とカテゴリ列を取得\nnum_col = []\ncat_col = []\n\ntrain_df = train_df.drop([\"id\",\"y\"],axis=1)\n\nfor col in train_df.columns:\n    if train_df[col].dtypes!=\"object\":\n        num_col.append(col)\n    else:\n        cat_col.append(col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:31.677188Z","iopub.execute_input":"2025-08-18T13:47:31.677463Z","iopub.status.idle":"2025-08-18T13:47:31.787873Z","shell.execute_reply.started":"2025-08-18T13:47:31.677441Z","shell.execute_reply":"2025-08-18T13:47:31.787027Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# all_df.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T04:13:12.598075Z","iopub.execute_input":"2025-08-16T04:13:12.598435Z","iopub.status.idle":"2025-08-16T04:13:12.613747Z","shell.execute_reply.started":"2025-08-16T04:13:12.598355Z","shell.execute_reply":"2025-08-16T04:13:12.612779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 訓練データとテストデータに分離\ntrain = all_df[:len(train_df)]\ntest = all_df[len(train_df):]\n\n# 訓練データをx,yに分割\nX_train = train.drop([\"id\",\"y\"],axis=1)\ny_train = train[\"y\"]\nX_test = test.drop([\"id\",\"y\"],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:34.367622Z","iopub.execute_input":"2025-08-18T13:47:34.367937Z","iopub.status.idle":"2025-08-18T13:47:34.505888Z","shell.execute_reply.started":"2025-08-18T13:47:34.367915Z","shell.execute_reply":"2025-08-18T13:47:34.504938Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ラベルエンコード\nfrom sklearn.preprocessing import LabelEncoder\n\nLE = LabelEncoder()\n\nfor col in X_train.columns:\n    if col in cat_col:\n        \n        # 訓練データでfit\n        LE.fit(X_train[col])\n\n        # 訓練・テストデータをそれぞれtransform\n        X_train[col] = LE.transform(X_train[col])\n        X_test[col] = LE.transform(X_test[col])\n\n# データフレーム変換\nX_train_df = pd.DataFrame(X_train,columns=cat_col)\nX_test_df = pd.DataFrame(X_test,columns=cat_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:34.626462Z","iopub.execute_input":"2025-08-18T13:47:34.627052Z","iopub.status.idle":"2025-08-18T13:47:36.883204Z","shell.execute_reply.started":"2025-08-18T13:47:34.627025Z","shell.execute_reply":"2025-08-18T13:47:36.882293Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 【Light GBM】","metadata":{}},{"cell_type":"code","source":"# ###################################################\n# ############ Light GBM ############################\n# ###################################################\n# import lightgbm as lgb\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import StratifiedKFold\n\n# # 学習、バリデーションデータ\n# pred_lgb = np.zeros(len(train_df))\n# pred_lgb_test = np.zeros(len(test_df))\n# models_lgb = []\n\n# # 入力データ\n# X = X_train\n# y = y_train\n\n# # 評価履歴を格納する辞書\n# evals_result_lgb = {}\n\n# # パラメータ\n# lgbm_params = {\n#     'objective': 'binary',\n#     \"device\": \"cpu\",\n#     # \"device\": \"gpu\",\n#     'metric': 'auc',\n#     'verbose': -1,              # ログ出力の制御\n#     'boosting_type': 'gbdt',\n#     # 'learning_rate': 0.01,\n#     # 'feature_fraction': 0.6956717916553479,\n#     # 'num_leaves':       153,\n#     # 'bagging_fraction': 0.5279852787927486,\n#     # 'bagging_freq':     4,\n#     # 'lambda_l1':        0.004603414256652151,\n#     # 'lambda_l2':        0.013858762846118894,\n#     # 'min_data_in_leaf': 87,\n#     }\n\n# # クロスバリデーション\n# # kf = KFold(n_splits=5, shuffle=True, random_state=42)\n# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# # for fold,(train_idx,valid_idx) in enumerate(kf.split(X)):\n# for fold,(train_idx,valid_idx) in enumerate(skf.split(X,y)):\n\n#     print(\"#\"*25)\n#     print(f\"### Folf {fold+1}\")\n#     print(\"#\"*25)\n    \n#     X_train_kf = X.iloc[train_idx,:]\n#     y_train_kf = y.iloc[train_idx]\n#     X_valid_kf = X.iloc[valid_idx,:]\n#     y_valid_kf = y.iloc[valid_idx]\n    \n#     # データセット作成\n#     lgb_train_lgb = lgb.Dataset(X_train_kf,y_train_kf)\n#     lgb_valid_lgb = lgb.Dataset(X_valid_kf,y_valid_kf)\n\n\n#     # 学習\n#     model_lgb = lgb.train(\n#         lgbm_params,\n#         lgb_train_lgb,\n#         num_boost_round=2000,\n#         valid_sets=[lgb_train_lgb,lgb_valid_lgb],\n#         valid_names=[\"train\",\"valid\"],\n#         callbacks=[\n#             lgb.early_stopping(stopping_rounds=100,verbose=False),\n#             lgb.record_evaluation(evals_result_lgb),\n#             lgb.log_evaluation(100),])\n\n#     # 各foldでのバリデーション予測\n#     pred_lgb[valid_idx] = model_lgb.predict(\n#         X_valid_kf, num_iteration=model_lgb.best_iteration)\n    \n#     # モデルの追加\n#     models_lgb.append(model_lgb)\n\n#     # テストの予測\n#     pred_lgb_test = pred_lgb_test + model_lgb.predict(\n#         X_test, num_iteration=model_lgb.best_iteration)\n\n# # FOLD数で割る\n# pred_lgb_test = pred_lgb_test/5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T12:05:39.885314Z","iopub.execute_input":"2025-08-17T12:05:39.885672Z","iopub.status.idle":"2025-08-17T12:11:28.974047Z","shell.execute_reply.started":"2025-08-17T12:05:39.885648Z","shell.execute_reply":"2025-08-17T12:11:28.973316Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 訓練データのスコア\n# from sklearn.metrics import f1_score\n# import matplotlib.pyplot as plt\n\n# AUC_lgb = roc_auc_score(y,pred_lgb)\n# F1_lgb = f1_score(y,np.round(pred_lgb,0))\n# print(f\"LGB: AUC score = {AUC_lgb}, F1 = {F1_lgb}\")\n\n# # 学習曲線\n# # lgb.plot_metric(evals_result_lgb,title=\"LightGBM AUC\",)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T12:14:17.680713Z","iopub.execute_input":"2025-08-17T12:14:17.681015Z","iopub.status.idle":"2025-08-17T12:14:18.694153Z","shell.execute_reply.started":"2025-08-17T12:14:17.680993Z","shell.execute_reply":"2025-08-17T12:14:18.693256Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = pred_lgb_test\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T12:13:23.130268Z","iopub.execute_input":"2025-08-17T12:13:23.130605Z","iopub.status.idle":"2025-08-17T12:13:23.805979Z","shell.execute_reply.started":"2025-08-17T12:13:23.130582Z","shell.execute_reply":"2025-08-17T12:13:23.805175Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【XGBoost】","metadata":{}},{"cell_type":"code","source":"# #################################################\n# ############ XGBoost ############################\n# #################################################\n# import xgboost as xgb\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import StratifiedKFold\n\n# # 学習、バリデーションデータ\n# pred_xgb = np.zeros(len(train_df))\n# pred_xgb_test = np.zeros(len(test_df))\n# models_xgb = []\n\n# # 入力データ\n# X = X_train\n# y = y_train\n\n# # 評価履歴を保存する辞書\n# evals_result_xgb = {}\n\n# # パラメータ\n# xgb_params = {\n#     \"objective\": \"binary:logistic\",\n#     \"tree_method\": \"hist\",\n#     # \"tree_method\": \"gpu_hist\",\n#     # \"gpu_id\": 0,\n#     \"eval_metric\": \"auc\",\n# }\n\n# # クロスバリデーション\n# # kf = KFold(n_splits=5, shuffle=True, random_state=42)\n# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# # for fold, (train_idx,valid_idx) in enumerate(kf.split(X)):\n# for fold,(train_idx,valid_idx) in enumerate(skf.split(X,y)):\n\n#     print(\"#\"*25)\n#     print(f\"### Fold {fold+1}\")\n#     print(\"#\"*25)\n\n#     # foldごとの訓練、バリデーションデータ\n#     X_train_kf = X.iloc[train_idx,:]\n#     y_train_kf = y.iloc[train_idx]\n#     X_valid_kf = X.iloc[valid_idx,:]\n#     y_valid_kf = y.iloc[valid_idx]\n\n#     # DMatrixに変換\n#     dtrain = xgb.DMatrix(X_train_kf,label=y_train_kf)\n#     dvalid = xgb.DMatrix(X_valid_kf,label=y_valid_kf)\n\n#     # 学習\n#     model_xgb = xgb.train(\n#         xgb_params,\n#         dtrain,\n#         num_boost_round=2000,\n#         evals=[(dtrain,\"train\"),(dvalid,\"valid\")],\n#         early_stopping_rounds=100,\n#         evals_result=evals_result_xgb,\n#         verbose_eval=100,\n#     )\n\n#     # 各foldでのバリデーション予測\n#     pred_xgb[valid_idx] = model_xgb.predict(\n#         dvalid,\n#         iteration_range=(0,model_xgb.best_iteration+1))\n\n#     # モデルの追加\n#     models_xgb.append(model_xgb)\n\n#     # テストの予測\n#     dtest = xgb.DMatrix(X_test)\n#     pred_xgb_test = pred_xgb_test + model_xgb.predict(\n#         dtest,\n#         iteration_range=(0,model_xgb.best_iteration+1))\n\n# # FOLD数で割る\n# pred_xgb_test = pred_xgb_test/5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T12:31:04.905175Z","iopub.execute_input":"2025-08-17T12:31:04.905520Z","iopub.status.idle":"2025-08-17T12:33:48.448226Z","shell.execute_reply.started":"2025-08-17T12:31:04.905494Z","shell.execute_reply":"2025-08-17T12:33:48.447255Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 訓練データのスコア\n# from sklearn.metrics import f1_score\n\n# AUC_xgb = roc_auc_score(y,pred_xgb)\n# F1_xgb = f1_score(y,np.round(pred_xgb,0))\n# print(f\"XGB: AUC score = {AUC_xgb}, F1 = {F1_xgb}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T12:33:48.450880Z","iopub.execute_input":"2025-08-17T12:33:48.451167Z","iopub.status.idle":"2025-08-17T12:33:49.381105Z","shell.execute_reply.started":"2025-08-17T12:33:48.451144Z","shell.execute_reply":"2025-08-17T12:33:49.380192Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = pred_xgb_test\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T12:33:49.381989Z","iopub.execute_input":"2025-08-17T12:33:49.382353Z","iopub.status.idle":"2025-08-17T12:33:50.050226Z","shell.execute_reply.started":"2025-08-17T12:33:49.382330Z","shell.execute_reply":"2025-08-17T12:33:50.049203Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 学習曲線の描画\n# from matplotlib.pyplot as plt\n# epochs = len(evals_result_xgb['train']['auc'])\n# x_axis = range(0, epochs)\n\n# plt.figure()\n# plt.plot(x_axis, evals_result_xgb['train']['auc'], label='Train')\n# plt.plot(x_axis, evals_result_xgb['valid']['auc'], label='Validation')\n# plt.xlabel('Iteration')\n# plt.ylabel('AUC')\n# plt.title('XGBoost AUC')\n# plt.grid()\n# plt.legend()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:13:18.338091Z","iopub.status.idle":"2025-08-16T01:13:18.338467Z","shell.execute_reply.started":"2025-08-16T01:13:18.338270Z","shell.execute_reply":"2025-08-16T01:13:18.338286Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【CatBoost】","metadata":{}},{"cell_type":"code","source":"# #################################################\n# ############ CatBoost ############################\n# #################################################\n# from catboost import Pool, train\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import StratifiedKFold\n\n# # 学習、バリデーションデータ\n# pred_cb = np.zeros(len(train_df))\n# pred_cb_test = np.zeros(len(test_df))\n# models_cb = []\n\n# # 入力データ\n# X = X_train\n# y = y_train\n\n# # 履歴を保存\n# cb_auc_valid = []\n\n# cat_params = {\n#     \"loss_function\": \"Logloss\",\n#     \"eval_metric\": \"AUC\",\n#     # \"task_type\": \"CPU\",\n#     \"task_type\": \"GPU\",\n#     # \"devices\": \"0\",\n#     \"iterations\": 2000,\n#     \"verbose\": 100,\n# }\n\n# # クロスバリデーション\n# # kf = KFold(n_splits=5, shuffle=True, random_state=42)\n# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# # for fold, (train_idx,valid_idx) in enumerate(kf.split(X)):\n# for fold,(train_idx,valid_idx) in enumerate(skf.split(X,y)):\n\n#     print(\"#\"*25)\n#     print(f\"### Fold {fold+1}\")\n#     print(\"#\"*25)\n    \n#     X_train_kf = X.iloc[train_idx,:]\n#     y_train_kf = y.iloc[train_idx]\n#     X_valid_kf = X.iloc[valid_idx,:]\n#     y_valid_kf = y.iloc[valid_idx]    \n\n#     # object型をカテゴリ型に変換\n#     for col in cat_col:\n#         X_train_kf.loc[:,col] = X_train_kf.loc[:,col].astype(\"category\")\n#         X_valid_kf.loc[:,col] = X_valid_kf.loc[:,col].astype(\"category\")\n\n#     # データセット設定\n#     train_pool = Pool(X_train_kf,y_train_kf,cat_features=cat_col)\n#     valid_pool = Pool(X_valid_kf,y_valid_kf,cat_features=cat_col)\n\n#     # 学習\n#     model_cb = train(\n#         params=cat_params,\n#         dtrain=train_pool,\n#         eval_set=valid_pool,\n#         early_stopping_rounds=100)\n\n#     # 各foldでのバリデーション予測\n#     pred_cb[valid_idx] = model_cb.predict(X_valid_kf,\n#         ntree_end=model_cb.best_iteration_,\n#         prediction_type=\"Probability\"\n#     )[:,1]\n    \n\n#     # モデルを追加\n#     models_cb.append(model_cb)\n\n#     evals_result = model_cb.get_evals_result()\n#     cb_auc_valid.append(evals_result[\"validation\"][\"AUC\"])\n\n#     # テストの予測\n#     pred_cb_test = pred_cb_test + model_cb.predict(X_test,\n#         ntree_end=model_cb.best_iteration_,\n#         prediction_type=\"Probability\"\n#     )[:,1]\n\n# # FOLD数で割る\n# pred_cb_test = pred_cb_test/5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T13:12:34.920417Z","iopub.execute_input":"2025-08-17T13:12:34.921191Z","iopub.status.idle":"2025-08-17T13:20:49.743810Z","shell.execute_reply.started":"2025-08-17T13:12:34.921162Z","shell.execute_reply":"2025-08-17T13:20:49.742950Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.metrics import f1_score\n\n# # スコア表示\n# AUC_cb = roc_auc_score(y,pred_cb)\n# F1_cb = f1_score(y,np.round(pred_cb,0))\n# print(f\"CB: AUC score = {AUC_cb}, F1 = {F1_cb}\")\n\n# # 学習履歴を一番短いfoldに揃える\n# min_len = min(len(m) for m in cb_auc_valid)\n# cb_auc_score = [m[:min_len] for m in cb_auc_valid]\n\n# # foldごとの結果を平均する\n# cb_auc_score = np.average(cb_auc_score,axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T13:20:49.745427Z","iopub.execute_input":"2025-08-17T13:20:49.745801Z","iopub.status.idle":"2025-08-17T13:20:50.921600Z","shell.execute_reply.started":"2025-08-17T13:20:49.745777Z","shell.execute_reply":"2025-08-17T13:20:50.920719Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = pred_cb_test\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T13:20:50.922555Z","iopub.execute_input":"2025-08-17T13:20:50.922814Z","iopub.status.idle":"2025-08-17T13:20:51.636276Z","shell.execute_reply.started":"2025-08-17T13:20:50.922780Z","shell.execute_reply":"2025-08-17T13:20:51.635377Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import  matplotlib.pyplot as plt\n# # 履歴の可視化\n# plt.plot(cb_auc_score, label='Validation')\n# plt.xlabel('Iteration')\n# plt.ylabel('AUC')\n# plt.grid()\n# plt.legend()\n# plt.title(\"CabBoost AUC\")\n# plt.show()","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【Neural Net】","metadata":{}},{"cell_type":"code","source":"import random\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\n# pytorch実装\nimport torch # Tensorの作成や操作\nimport torch.nn as nn # ニューラルネットワーク\nimport torch.nn.functional as F # 関数をメソッドとして提供\nimport torch.optim as optim # オプティマイザ\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport time\n\n# GPUの使用状況確認\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# データフレーム読み込み\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\n\n# 設定\nSEED = 42\nCATEGORICAL = cat_col\nNUMERICAL = num_col\nTARGET = \"y\"\nUSE = CATEGORICAL + NUMERICAL\ndf_train = train_df.drop(\"id\",axis=1)\ndf_test = test_df.drop(\"id\",axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:42.309602Z","iopub.execute_input":"2025-08-18T13:47:42.310043Z","iopub.status.idle":"2025-08-18T13:47:49.013736Z","shell.execute_reply.started":"2025-08-18T13:47:42.310015Z","shell.execute_reply":"2025-08-18T13:47:49.012840Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# 標準化 + ラベルエンコード\ndef preprocessing(df_train, df_test, cat_cols=CATEGORICAL, num_cols=NUMERICAL, target=TARGET):\n\n    # 訓練データ + テストデータ\n    df = pd.concat([df_train.drop(columns=target), df_test])\n    y = df_train[target]\n    train_len = len(df_train)\n    \n    # 欠損埋め\n    df[cat_cols] = df[cat_cols].fillna('None')\n    df[num_cols] = df[num_cols].fillna(0)\n\n    train = df[:train_len]\n    test = df[train_len:]\n\n    # 標準化\n    scaler = StandardScaler()\n\n    # フィッティング\n    # scaler.fit(df[num_cols])\n    scaler.fit(train[num_cols])\n\n    # 適用\n    train[num_cols] = scaler.transform(train[num_cols])\n    test[num_cols] = scaler.transform(test[num_cols])\n    df = pd.concat([train, test])\n    \n    # ラベルエンコーダ\n    for col in df.columns:\n        if col in cat_cols:\n            df[col] = LabelEncoder().fit_transform(df[col])\n            df[col]= df[col].astype('category')\n            \n    return pd.concat([df.iloc[:train_len], y], axis=1), df.iloc[train_len:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:49.015270Z","iopub.execute_input":"2025-08-18T13:47:49.015611Z","iopub.status.idle":"2025-08-18T13:47:49.022668Z","shell.execute_reply.started":"2025-08-18T13:47:49.015578Z","shell.execute_reply":"2025-08-18T13:47:49.021942Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# データセット関数\nclass CustomDataset(Dataset):\n\n    # オブジェクト定義\n    def __init__(self, df, target, cat_cols=CATEGORICAL):\n        self.df_cat = df[cat_cols]\n        self.df_num = df.drop(cat_cols, axis=1)\n        self.X_cats = self.df_cat.values.astype(np.int64)\n        self.X_nums = self.df_num.values.astype(np.float32)\n        self.target = target.values.astype(np.int64)\n\n    # データセットのサイズを返す\n    def __len__(self):\n        return len(self.target)\n\n    # 指定したインデックスのデータとラベルを返す\n    def __getitem__(self, idx):\n        return [self.X_cats[idx], self.X_nums[idx], self.target[idx]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:49.023513Z","iopub.execute_input":"2025-08-18T13:47:49.023894Z","iopub.status.idle":"2025-08-18T13:47:49.063215Z","shell.execute_reply.started":"2025-08-18T13:47:49.023863Z","shell.execute_reply":"2025-08-18T13:47:49.062347Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# NNモデル作成\nclass NN_Model(nn.Module):\n\n    # ネットワーク構造の定義\n    def __init__(self, embedding_sizes, n_num):\n        super().__init__()\n        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories, size in embedding_sizes])\n        n_emb = sum(e.embedding_dim for e in self.embeddings)\n        self.n_emb, self.n_num = n_emb, n_num\n        self.lin1 = nn.Linear(self.n_emb + self.n_num, 100)\n        self.lin2 = nn.Linear(100, 70)\n        self.lin3 = nn.Linear(70, 2)\n        self.bn1 = nn.BatchNorm1d(self.n_num)\n        self.bn2 = nn.BatchNorm1d(100)\n        self.bn3 = nn.BatchNorm1d(70)\n        self.emb_drop = nn.Dropout(0.6)\n        self.drops = nn.Dropout(0.3)\n \n    # 順伝播\n    def forward(self,x_cat,x_num):\n        x = [e(x_cat[:, i]) for i, e in enumerate(self.embeddings)]\n        x = torch.cat(x, dim=1)\n        x = self.emb_drop(x)\n        x2 = self.bn1(x_num)\n        x = torch.cat([x, x2], dim=1)\n        x = F.relu(self.lin1(x))\n        x = self.drops(x)\n        x = self.bn2(x)\n        x = F.relu(self.lin2(x))\n        x = self.drops(x)\n        x = self.bn3(x)\n        x = self.lin3(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:49.064553Z","iopub.execute_input":"2025-08-18T13:47:49.064841Z","iopub.status.idle":"2025-08-18T13:47:49.083248Z","shell.execute_reply.started":"2025-08-18T13:47:49.064813Z","shell.execute_reply":"2025-08-18T13:47:49.082250Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# 前処理の実施\ndf_train, df_test = preprocessing(df_train, df_test)\n\n# ラベルエンコード済みカテゴリ変数の埋め込み\n# 各カテゴリ列の変数の種類\ncat_sizes = [len(df_train[col].cat.categories) for col in CATEGORICAL]\n\n# (入力サイズ, 50と割る2の小さい方)でエンコード\nemb_sizes = [(size, min(50, (size+1)//2)) for size in cat_sizes]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:50.417293Z","iopub.execute_input":"2025-08-18T13:47:50.417568Z","iopub.status.idle":"2025-08-18T13:47:53.566586Z","shell.execute_reply.started":"2025-08-18T13:47:50.417548Z","shell.execute_reply":"2025-08-18T13:47:53.565966Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1479464330.py:24: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train[num_cols] = scaler.transform(train[num_cols])\n/tmp/ipykernel_36/1479464330.py:25: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test[num_cols] = scaler.transform(test[num_cols])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 記録用\nhist = {\n    'train_loss': [], 'train_auc': [],\n    'val_loss': [], 'val_auc': []\n}\n\n# パラメータ\nbs = 64 # バッチサイズ\nEPOCHS = 10 # エポック\nFOLDS = 5 # FOLD数\nLR=1e-3 # 学習率\n\n# stratified KFoldの宣言\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\nfold_results = []\n\ntest_results = []\n\n# SKFによるデータ分割\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df_train.drop(columns=TARGET), df_train[TARGET])):\n    \n    print(f\"\\n========== Fold {fold+1} ==========\")\n\n    # 学習データ\n    X_train = df_train.drop(columns=TARGET).iloc[train_idx] \n    y_train = df_train[TARGET].iloc[train_idx]\n\n    # バリデーションデータ\n    X_val = df_train.drop(columns=TARGET).iloc[val_idx]\n    y_val = df_train[TARGET].iloc[val_idx]\n\n    # Datasetの作成\n    train_dataset = CustomDataset(X_train, y_train)\n    val_dataset = CustomDataset(X_val, y_val)\n    \n    # DataLoaderの作成\n    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n\n    # モデル構築\n    model = NN_Model(emb_sizes, len(NUMERICAL)).to(device)\n\n    # 最適化設定\n    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n    # 損失関数\n    criterion = nn.CrossEntropyLoss()\n\n    hist = {\"train_auc\": [], \"val_auc\": []}\n\n    # 学習・予測エポックのループ\n    for epoch in range(EPOCHS):\n\n        # 開始時間\n        start_time = time.time()\n\n        # 学習モード\n        model.train()\n\n        # ラベル、予測値の保存場所\n        y_true_train, y_pred_train = [], []\n\n        # プログレスバー\n        train_iter = tqdm(train_loader, desc=f\"<Train> Epoch {epoch+1}\", leave=False)\n        \n        for cat_data, num_data, target in train_iter:\n\n            # DataLoaderから取り出した、カテゴリ、数値、ターゲット\n            cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n\n            # パラメータの勾配を初期化\n            optimizer.zero_grad()\n\n            # 予測値の算出\n            output = model(cat_data, num_data)\n\n            # ラベルと予測値とのロス計算\n            loss = criterion(output, target)\n\n            # 各パラメータの勾配を算出\n            loss.backward()\n\n            # パラメータ更新\n            optimizer.step()\n\n            # ソフトマックスの分類結果を格納\n            probs = torch.softmax(output, dim=1)[:, 1].detach().cpu().numpy()\n            y_pred_train.extend(probs)\n\n            # ラベルの格納\n            y_true_train.extend(target.cpu().numpy())\n\n            # プログレスバーの後ろにロス値を表示\n            train_iter.set_postfix(loss=loss.item())\n\n        # histに残すAUCスコア\n        train_auc = roc_auc_score(y_true_train, y_pred_train)\n\n        # 評価モード\n        model.eval()\n\n        # ラベル、予測値の保存場所        \n        y_true_val, y_pred_val = [], []\n\n        # プログレスバー\n        val_iter = tqdm(val_loader, desc=f\"<Val> Epoch {epoch+1}\", leave=False)\n\n        # 勾配を更新しない\n        with torch.no_grad():\n            \n            for cat_data, num_data, target in val_iter:\n    \n                # DataLoaderから取り出した、カテゴリ、数値、ターゲット\n                cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n\n                # 予測値の算出\n                output = model(cat_data, num_data)\n\n                # ソフトマックスの分類結果を格納\n                probs = torch.softmax(output, dim=1)[:, 1].cpu().numpy()\n                y_pred_val.extend(probs)\n\n                # ラベルの格納\n                y_true_val.extend(target.cpu().numpy())\n\n                # プログレスバーの後ろにロス値を表示\n                val_iter.set_postfix(loss=criterion(output, target).item())\n\n        # histに残すAUCスコア        \n        val_auc = roc_auc_score(y_true_val, y_pred_val)\n\n        # 差分時刻\n        elapsed = time.time() - start_time\n\n        # 履歴追加\n        hist[\"train_auc\"].append(train_auc)\n        hist[\"val_auc\"].append(val_auc)\n\n        # 進捗\n        print(f\"Epoch {epoch+1}/{EPOCHS} - TrainAUC: {train_auc:.4f} | ValAUC: {val_auc:.4f} | Time: {elapsed:.1f}s\")\n\n    # foldごとに保存\n    torch.save(model.state_dict(), f\"model_fold{fold+1}.pth\")\n    \n    # ヒストグラムの更新\n    fold_results.append(hist)\n\n    # foldごとにテストデータ計算\n    model.eval()\n    with torch.no_grad():\n        X_test_cat = torch.from_numpy(df_test[CATEGORICAL].values.astype(np.int64)).to(device)\n        X_test_num = torch.from_numpy(df_test[NUMERICAL].values.astype(np.float32)).to(device)\n\n        # 予測\n        preds = torch.softmax(model(X_test_cat, X_test_num),dim=1)[:,1].cpu().numpy()\n        # preds = torch.softmax(model(X_test_cat, X_test_num).squeeze()).cpu().numpy()\n        test_results.append(preds)\n    \n# shape = (n_folds, n_test_samples) → 平均化\ntest_results = np.mean(test_results, axis=0)        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:47:53.567948Z","iopub.execute_input":"2025-08-18T13:47:53.568246Z"}},"outputs":[{"name":"stdout","text":"\n========== Fold 1 ==========\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - TrainAUC: 0.9187 | ValAUC: 0.9503 | Time: 62.5s\n","output_type":"stream"},{"name":"stderr","text":"<Val> Epoch 2:  62%|██████▏   | 1444/2344 [00:04<00:02, 330.46it/s, loss=0.237]   ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"len(test_results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 提出データ作成\nsample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\nsample_submission['y'] = test_results\nsample_submission.to_csv('submission.csv', index=False)\nprint('Submission file saved.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ======================\n# # FoldごとのAUCをプロット\n# # ======================\n# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10,5))\n# for i, hist in enumerate(fold_results):\n#     plt.plot(hist[\"val_auc\"], label=f\"Fold {i+1} Val AUC\")\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"AUC\")\n# plt.legend()\n# plt.title(\"Validation AUC per Fold\")\n# plt.show() ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = pred_lgb_test\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 検証データの誤差の可視化\n# train_loss = hist['train_loss']\n# val_loss = hist['val_loss']\n\n# fig = plt.figure()\n# plt.rc('font', family='serif')\n# plt.plot(range(len(train_loss)), train_loss, linewidth=1, label='train_loss')\n# plt.plot(range(len(val_loss)), val_loss, color='red', linewidth=1, label='val_loss')\n# plt.xlabel('epochs')\n# plt.ylabel('loss')\n# plt.legend()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T06:27:33.108004Z","iopub.execute_input":"2025-08-17T06:27:33.108723Z","iopub.status.idle":"2025-08-17T06:27:33.277372Z","shell.execute_reply.started":"2025-08-17T06:27:33.108698Z","shell.execute_reply":"2025-08-17T06:27:33.275948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(f'validation data best acc : {best_acc}')\n\n# # 検証データの精度の可視化\n# train_acc = hist['train_accuracy']\n# val_acc = hist['val_accuracy']\n\n# fig = plt.figure()\n# plt.rc('font', family='serif')\n# plt.plot(range(len(train_acc)), train_acc, linewidth=1, label='train_acc')\n# plt.plot(range(len(val_acc)), val_acc, color='red', linewidth=1, label='val_acc')\n# plt.xlabel('epochs')\n# plt.ylabel('accuracy')\n# plt.legend()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T06:27:33.278326Z","iopub.execute_input":"2025-08-17T06:27:33.278595Z","iopub.status.idle":"2025-08-17T06:27:33.442411Z","shell.execute_reply.started":"2025-08-17T06:27:33.278576Z","shell.execute_reply":"2025-08-17T06:27:33.441350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 記録用\n# hist = {\n#     'train_loss': [], 'train_auc': [],\n#     'val_loss': [], 'val_auc': []\n# }\n\n# # パラメータ\n# bs = 64 # バッチサイズ\n# EPOCHS = 5 # エポック\n# FOLDS = 5 # FOLD数\n# LR=1e-3 # 学習率\n\n# # stratified KFoldの宣言\n# skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\n# fold_results = []\n\n# for fold, (train_idx, val_idx) in enumerate(skf.split(df_train.drop(columns=TARGET), df_train[TARGET])):\n    \n#     print(f\"\\n========== Fold {fold+1} ==========\")\n\n#     # データ分割\n#     X_train, X_val = df_train.drop(columns=TARGET).iloc[train_idx], df_train.drop(columns=TARGET).iloc[val_idx]\n#     y_train, y_val = df_train[TARGET].iloc[train_idx], df_train[TARGET].iloc[val_idx]\n\n#     # Dataset / DataLoader\n#     train_dataset = CustomDataset(X_train, y_train)\n#     val_dataset = CustomDataset(X_val, y_val)\n#     train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n#     val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n\n#     # モデル・最適化・損失\n#     model = NN_Model(emb_sizes, len(NUMERICAL)).to(device)\n#     optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n#     criterion = nn.CrossEntropyLoss()\n\n#     hist = {\"train_auc\": [], \"val_auc\": []}\n\n#     for epoch in range(EPOCHS):\n#         start_time = time.time()\n\n#         # ===== 学習 =====\n#         model.train()\n#         y_true_train, y_pred_train = [], []\n#         train_iter = tqdm(train_loader, desc=f\"<Train> Epoch {epoch+1}\", leave=False)\n#         for cat_data, num_data, target in train_iter:\n#             cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n\n#             optimizer.zero_grad()\n#             output = model(cat_data, num_data)\n#             loss = criterion(output, target)\n#             loss.backward()\n#             optimizer.step()\n\n#             probs = torch.softmax(output, dim=1)[:, 1].detach().cpu().numpy()\n#             y_pred_train.extend(probs)\n#             y_true_train.extend(target.cpu().numpy())\n#             train_iter.set_postfix(loss=loss.item())\n\n#         train_auc = roc_auc_score(y_true_train, y_pred_train)\n\n#         # ===== 検証 =====\n#         model.eval()\n#         y_true_val, y_pred_val = [], []\n#         val_iter = tqdm(val_loader, desc=f\"<Val> Epoch {epoch+1}\", leave=False)\n#         with torch.no_grad():\n#             for cat_data, num_data, target in val_iter:\n#                 cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n#                 output = model(cat_data, num_data)\n#                 probs = torch.softmax(output, dim=1)[:, 1].cpu().numpy()\n#                 y_pred_val.extend(probs)\n#                 y_true_val.extend(target.cpu().numpy())\n#                 val_iter.set_postfix(loss=criterion(output, target).item())\n\n#         val_auc = roc_auc_score(y_true_val, y_pred_val)\n#         elapsed = time.time() - start_time\n\n#         hist[\"train_auc\"].append(train_auc)\n#         hist[\"val_auc\"].append(val_auc)\n\n#         print(f\"Epoch {epoch+1}/{EPOCHS} - TrainAUC: {train_auc:.4f} | ValAUC: {val_auc:.4f} | Time: {elapsed:.1f}s\")\n\n#     fold_results.append(hist)\n\n#     # テストデータ\n\n# # ======================\n# # FoldごとのAUCをプロット\n# # ======================\n# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10,5))\n# for i, hist in enumerate(fold_results):\n#     plt.plot(hist[\"val_auc\"], label=f\"Fold {i+1} Val AUC\")\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"AUC\")\n# plt.legend()\n# plt.title(\"Validation AUC per Fold\")\n# plt.show() ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}