{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# S5E8_00_Baseline\n# 単純モデルの作成(LGBM,XGB,CatBoost)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:08:33.322071Z","iopub.execute_input":"2025-08-16T01:08:33.322409Z","iopub.status.idle":"2025-08-16T01:08:33.326585Z","shell.execute_reply.started":"2025-08-16T01:08:33.322387Z","shell.execute_reply":"2025-08-16T01:08:33.325545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ライブラリのインポート\nimport numpy as np\nimport pandas as pd\nimport os\n\n# データフレーム読み込み\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\n\n# データ結合\nall_df = pd.concat([train_df,test_df],axis=0,ignore_index=True)\nmax_row = len(all_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:41:42.245377Z","iopub.execute_input":"2025-08-17T05:41:42.245984Z","iopub.status.idle":"2025-08-17T05:41:44.743634Z","shell.execute_reply.started":"2025-08-17T05:41:42.245955Z","shell.execute_reply":"2025-08-17T05:41:44.742511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# all_df.info() # 特徴量、欠損、型確認","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T04:05:32.136041Z","iopub.execute_input":"2025-08-16T04:05:32.136413Z","iopub.status.idle":"2025-08-16T04:05:32.643085Z","shell.execute_reply.started":"2025-08-16T04:05:32.136355Z","shell.execute_reply":"2025-08-16T04:05:32.642114Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T03:01:12.573520Z","iopub.execute_input":"2025-08-16T03:01:12.573762Z","iopub.status.idle":"2025-08-16T03:01:12.600181Z","shell.execute_reply.started":"2025-08-16T03:01:12.573744Z","shell.execute_reply":"2025-08-16T03:01:12.599000Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 数値列とカテゴリ列を取得\nnum_col = []\ncat_col = []\n\ntrain_df2 = train_df.drop([\"id\",\"y\"],axis=1)\n\nfor col in train_df2.columns:\n    if train_df2[col].dtypes!=\"object\":\n        num_col.append(col)\n    else:\n        cat_col.append(col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:04.650391Z","iopub.execute_input":"2025-08-17T05:01:04.651813Z","iopub.status.idle":"2025-08-17T05:01:04.745414Z","shell.execute_reply.started":"2025-08-17T05:01:04.651750Z","shell.execute_reply":"2025-08-17T05:01:04.744206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_col","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:02:15.055095Z","iopub.execute_input":"2025-08-17T05:02:15.055490Z","iopub.status.idle":"2025-08-17T05:02:15.062586Z","shell.execute_reply.started":"2025-08-17T05:02:15.055462Z","shell.execute_reply":"2025-08-17T05:02:15.061819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# all_df.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T04:13:12.598075Z","iopub.execute_input":"2025-08-16T04:13:12.598435Z","iopub.status.idle":"2025-08-16T04:13:12.613747Z","shell.execute_reply.started":"2025-08-16T04:13:12.598355Z","shell.execute_reply":"2025-08-16T04:13:12.612779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 訓練データとテストデータに分離\ntrain = all_df[:len(train_df)]\ntest = all_df[len(train_df):]\n\n# 訓練データをx,yに分割\nX = train.drop([\"id\",\"y\"],axis=1)\ny = train[\"y\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:01:09.259368Z","iopub.execute_input":"2025-08-17T05:01:09.259668Z","iopub.status.idle":"2025-08-17T05:01:09.358921Z","shell.execute_reply.started":"2025-08-17T05:01:09.259646Z","shell.execute_reply":"2025-08-17T05:01:09.357878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ラベルエンコード\nfrom sklearn.preprocessing import LabelEncoder\n\nLE = LabelEncoder()\n\n# 訓練データでfit\nLE.fit(train_df[num_col])\n\n# 訓練・テストデータをそれぞれtransform\nLE_train = LE.transform(train_df[col])\nLE_test = LE.transform(test_df[col])\n\n# データフレーム変換\nLE_train_df = pd.DataFrame(\n    LE_train,columns=LE.get_feature_names_out(cat_col))\nLE_test_df = pd.DataFrame(\n    LE_test,columns=LE.get_feature_names_out(cat_col))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T08:27:30.007995Z","iopub.execute_input":"2025-08-16T08:27:30.008428Z","iopub.status.idle":"2025-08-16T08:27:32.341286Z","shell.execute_reply.started":"2025-08-16T08:27:30.008394Z","shell.execute_reply":"2025-08-16T08:27:32.340419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###################################################\n############ Light GBM ############################\n###################################################\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\n\n# 学習、バリデーションデータ\npred_lgb = np.zeros(len(train_df))\nmodels_lgb = []\n\n# 評価履歴を格納する辞書\nevals_result_lgb = {}\n\n# パラメータ\nlgbm_params = {\n    'objective': 'binary',\n    \"device\": \"cpu\",\n    # \"device\": \"gpu\",\n    'metric': 'auc',\n    'verbose': -1,              # ログ出力の制御\n    'boosting_type': 'gbdt',\n    # 'learning_rate': 0.01,\n    # 'feature_fraction': 0.6956717916553479,\n    # 'num_leaves':       153,\n    # 'bagging_fraction': 0.5279852787927486,\n    # 'bagging_freq':     4,\n    # 'lambda_l1':        0.004603414256652151,\n    # 'lambda_l2':        0.013858762846118894,\n    # 'min_data_in_leaf': 87,\n    }\n\n# クロスバリデーション\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold,(train_idx,valid_idx) in enumerate(kf.split(X)):\n\n    print(\"#\"*25)\n    print(f\"### Folf {fold+1}\")\n    print(\"#\"*25)\n    \n    X_train_kf = X.iloc[train_idx,:]\n    y_train_kf = y.iloc[train_idx]\n    X_valid_kf = X.iloc[valid_idx,:]\n    y_valid_kf = y.iloc[valid_idx]\n    \n    # データセット作成\n    lgb_train_lgb = lgb.Dataset(X_train_kf,y_train_kf)\n    lgb_valid_lgb = lgb.Dataset(X_valid_kf,y_valid_kf)\n\n\n    # 学習\n    model_lgb = lgb.train(\n        lgbm_params,\n        lgb_train_lgb,\n        num_boost_round=2000,\n        valid_sets=[lgb_train_lgb,lgb_valid_lgb],\n        valid_names=[\"train\",\"valid\"],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=100,verbose=False),\n            lgb.record_evaluation(evals_result_lgb),\n            lgb.log_evaluation(100),])\n\n    # 各foldでのバリデーション予測\n    pred_lgb[valid_idx] = model_lgb.predict(\n        X_valid_kf, num_iteration=model_lgb.best_iteration)\n    \n    # モデルの追加\n    models_lgb.append(model_lgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:08:37.525542Z","iopub.execute_input":"2025-08-16T01:08:37.525833Z","iopub.status.idle":"2025-08-16T01:13:18.324890Z","shell.execute_reply.started":"2025-08-16T01:08:37.525805Z","shell.execute_reply":"2025-08-16T01:13:18.324164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_lgb.predict(X, num_iteration=models_lgb[0].best_iteration)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:16:34.037878Z","iopub.execute_input":"2025-08-16T01:16:34.038524Z","iopub.status.idle":"2025-08-16T01:16:43.793180Z","shell.execute_reply.started":"2025-08-16T01:16:34.038497Z","shell.execute_reply":"2025-08-16T01:16:43.792491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 訓練データのスコア\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n\nAUC_lgb = roc_auc_score(y,pred_lgb)\nF1_lgb = f1_score(y,np.round(pred_lgb,0))\nprint(f\"LGB: AUC score = {AUC_lgb}, F1 = {F1_lgb}\")\n\n# 学習曲線\nlgb.plot_metric(evals_result_lgb,\n                title=\"LightGBM AUC\",)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:15:50.860933Z","iopub.execute_input":"2025-08-16T01:15:50.861299Z","iopub.status.idle":"2025-08-16T01:15:52.117020Z","shell.execute_reply.started":"2025-08-16T01:15:50.861277Z","shell.execute_reply":"2025-08-16T01:15:52.116181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#################################################\n############ XGBoost ############################\n#################################################\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\n\n# 学習、バリデーションデータ\npred_xgb = np.zeros(len(train_df))\nmodels_xgb = []\n\n# 評価履歴を保存する辞書\nevals_result_xgb = {}\n\n# パラメータ\nxgb_params = {\n    \"objective\": \"binary:logistic\",\n    \"tree_method\": \"hist\",\n    # \"tree_method\": \"gpu_hist\",\n    # \"gpu_id\": 0,\n    \"eval_metric\": \"auc\",\n}\n\n# クロスバリデーション\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {fold+1}\")\n    print(\"#\"*25)\n\n    # foldごとの訓練、バリデーションデータ\n    X_train_kf = X.iloc[train_idx,:]\n    y_train_kf = y.iloc[train_idx]\n    X_valid_kf = X.iloc[valid_idx,:]\n    y_valid_kf = y.iloc[valid_idx]\n\n    # DMatrixに変換\n    dtrain = xgb.DMatrix(X_train_kf,label=y_train_kf)\n    dvalid = xgb.DMatrix(X_valid_kf,label=y_valid_kf)\n\n    # 学習\n    model_xgb = xgb.train(\n        xgb_params,\n        dtrain,\n        num_boost_round=2000,\n        evals=[(dtrain,\"train\"),(dvalid,\"valid\")],\n        early_stopping_rounds=100,\n        evals_result_xgb=evals_result,\n        verbose_eval=100,\n    )\n\n    # 各foldでのバリデーション予測\n    pred_xgb[valid_idx] = model_xgb.predict(\n        dvalid,\n        iteration_range=(0,model_xgb.best_iteration+1))\n\n    # モデルの追加\n    models_xgb.append(model_xgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:13:18.335480Z","iopub.status.idle":"2025-08-16T01:13:18.335861Z","shell.execute_reply.started":"2025-08-16T01:13:18.335624Z","shell.execute_reply":"2025-08-16T01:13:18.335640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 訓練データのスコア\nfrom sklearn.metrics import f1_score\n\nAUC_xgb = roc_auc_score(y,pred_xgb)\nF1_xgb = f1_score(y,np.round(pred_xgb,0))\nprint(f\"XGB: AUC score = {AUC_xgb}, F1 = {F1_xgb}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:13:18.336758Z","iopub.status.idle":"2025-08-16T01:13:18.337022Z","shell.execute_reply.started":"2025-08-16T01:13:18.336890Z","shell.execute_reply":"2025-08-16T01:13:18.336903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 学習曲線の描画\nfrom matplotlib.pyplot as plt\nepochs = len(evals_result_xgb['train']['auc'])\nx_axis = range(0, epochs)\n\nplt.figure()\nplt.plot(x_axis, evals_result_xgb['train']['auc'], label='Train')\nplt.plot(x_axis, evals_result_xgb['valid']['auc'], label='Validation')\nplt.xlabel('Iteration')\nplt.ylabel('AUC')\nplt.title('XGBoost AUC')\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T01:13:18.338091Z","iopub.status.idle":"2025-08-16T01:13:18.338467Z","shell.execute_reply.started":"2025-08-16T01:13:18.338270Z","shell.execute_reply":"2025-08-16T01:13:18.338286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#################################################\n############ CatBoost ############################\n#################################################\nfrom catboost import Pool, train\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\n\n# 学習、バリデーションデータ\npred_cb = np.zeros(len(train_df))\nmodels_cb = []\n\n# 履歴を保存\ncb_auc_valid = []\n\ncat_params = {\n    \"loss_function\": \"Logloss\",\n    \"eval_metric\": \"AUC\",\n    \"task_type\": \"CPU\",\n    # \"task_type\": \"GPU\",\n    # \"devices\": \"0\",\n    \"iterations\": 2000,\n    \"verbose\": 100,\n}\n\n# クロスバリデーション\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {fold+1}\")\n    print(\"#\"*25)\n    \n    X_train_kf = X.iloc[train_idx,:]\n    y_train_kf = y.iloc[train_idx]\n    X_valid_kf = X.iloc[valid_idx,:]\n    y_valid_kf = y.iloc[valid_idx]    \n\n    # object型をカテゴリ型に変換\n    for col in cat_col:\n        X_train_kf.loc[:,col] = X_train_kf.loc[:,col].astype(\"category\")\n        X_valid_kf.loc[:,col] = X_valid_kf.loc[:,col].astype(\"category\")\n\n    # データセット設定\n    train_pool = Pool(X_train_kf,y_train_kf,cat_features=cat_col)\n    valid_pool = Pool(X_valid_kf,y_valid_kf,cat_features=cat_col)\n\n    # 学習\n    model_cb = train(\n        params=cat_params,\n        dtrain=train_pool,\n        eval_set=valid_pool,\n        early_stopping_rounds=100)\n\n    # 各foldでのバリデーション予測\n    pred_cb[valid_idx] = model_cb.predict(X_valid_kf,\n        ntree_end=model_cb.best_iteration_,\n        prediction_type=\"Probability\"\n    )[:,1]\n    \n\n    # モデルを追加\n    models_cb.append(model_cb)\n\n    evals_result = model_cb.get_evals_result()\n    cb_auc_valid.append(evals_result[\"validation\"][\"AUC\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T03:40:55.723435Z","iopub.execute_input":"2025-08-16T03:40:55.724051Z","iopub.status.idle":"2025-08-16T03:48:11.208527Z","shell.execute_reply.started":"2025-08-16T03:40:55.724027Z","shell.execute_reply":"2025-08-16T03:48:11.207644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# スコア表示\nAUC_cb = roc_auc_score(y,pred_cb)\nF1_cb = f1_score(y,np.round(pred_cb,0))\nprint(f\"CB: AUC score = {AUC_cb}, F1 = {F1_cb}\")\n\n# 学習履歴を一番短いfoldに揃える\nmin_len = min(len(m) for m in cb_auc_valid)\ncb_auc_score = [m[:min_len] for m in cb_auc_valid]\n\n# foldごとの結果を平均する\ncb_auc_score = np.average(cb_auc_score,axis=0)\n\nimport  matplotlib.pyplot as plt\n# 履歴の可視化\nplt.plot(cb_auc_score, label='Validation')\nplt.xlabel('Iteration')\nplt.ylabel('AUC')\nplt.grid()\nplt.legend()\nplt.title(\"CabBoost AUC\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T03:54:18.384962Z","iopub.execute_input":"2025-08-16T03:54:18.385544Z","iopub.status.idle":"2025-08-16T03:54:19.461234Z","shell.execute_reply.started":"2025-08-16T03:54:18.385516Z","shell.execute_reply":"2025-08-16T03:54:19.460636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T06:21:01.098730Z","iopub.execute_input":"2025-08-17T06:21:01.099015Z","iopub.status.idle":"2025-08-17T06:21:01.105291Z","shell.execute_reply.started":"2025-08-17T06:21:01.098993Z","shell.execute_reply":"2025-08-17T06:21:01.104022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pytorch実装\nimport torch # Tensorの作成や操作\nimport torch.nn as nn # ニューラルネットワーク\nimport torch.nn.functional as F # 関数をメソッドとして提供\nimport torch.optim as optim # オプティマイザ\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable\n\n# GPUの使用状況確認\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:41:58.693960Z","iopub.execute_input":"2025-08-17T05:41:58.694300Z","iopub.status.idle":"2025-08-17T05:41:58.701087Z","shell.execute_reply.started":"2025-08-17T05:41:58.694250Z","shell.execute_reply":"2025-08-17T05:41:58.700183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 設定\nSEED = 42\nCATEGORICAL = ['job','marital','education','default','housing',\n                'loan','contact','month','poutcome']\nNUMERICAL = ['age','balance','day','duration','campaign',\n             'pdays','previous']\nTAEGET = \"y\"\nUSE = cat_col + num_col\ndf_train = train_df.drop(\"id\",axis=1)\ndf_test = test_df.drop(\"id\",axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:47:22.319570Z","iopub.execute_input":"2025-08-17T05:47:22.319926Z","iopub.status.idle":"2025-08-17T05:47:22.424946Z","shell.execute_reply.started":"2025-08-17T05:47:22.319902Z","shell.execute_reply":"2025-08-17T05:47:22.423843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n# 前処理関数\ndef preprocessing(df_train, df_test, cat_cols=CATEGORICAL, num_cols=NUMERICAL, target=TARGET):\n\n    # 訓練データ + テストデータ\n    df = pd.concat([df_train.drop(columns=target), df_test])\n    y = df_train[target]\n    train_len = len(df_train)\n    \n    # 欠損埋め\n    df[cat_cols] = df[cat_cols].fillna('None')\n    df[num_cols] = df[num_cols].fillna(0)\n\n    # 標準化\n    scaler = StandardScaler()\n    scaler.fit(df[num_cols])\n    df[num_cols] = scaler.transform(df[num_cols])\n    \n    # ラベルエンコーダ\n    for col in df.columns:\n        if col in cat_cols:\n            df[col] = LabelEncoder().fit_transform(df[col])\n            df[col]= df[col].astype('category')\n            \n    return pd.concat([df.iloc[:train_len], y], axis=1), df.iloc[train_len:]\n\n# 前処理の実施\ndf_train, df_test = preprocessing(df_train, df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:47:24.498903Z","iopub.execute_input":"2025-08-17T05:47:24.499196Z","iopub.status.idle":"2025-08-17T05:47:27.148204Z","shell.execute_reply.started":"2025-08-17T05:47:24.499176Z","shell.execute_reply":"2025-08-17T05:47:27.146866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# out-of-fold\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(df_train.drop(columns=TARGET), df_train[TARGET], test_size=0.20, random_state=SEED, shuffle=True)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:47:27.149687Z","iopub.execute_input":"2025-08-17T05:47:27.149968Z","iopub.status.idle":"2025-08-17T05:47:27.286605Z","shell.execute_reply.started":"2025-08-17T05:47:27.149946Z","shell.execute_reply":"2025-08-17T05:47:27.285532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# embedding\ncat_sizes = [len(df_train[col].cat.categories) for col in cat_col]\nemb_sizes = [(size, min(50, (size+1)//2)) for size in cat_sizes]\nemb_sizes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:47:41.550177Z","iopub.execute_input":"2025-08-17T05:47:41.550480Z","iopub.status.idle":"2025-08-17T05:47:41.557974Z","shell.execute_reply.started":"2025-08-17T05:47:41.550460Z","shell.execute_reply":"2025-08-17T05:47:41.556962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\n# データセット関数\nclass ClassificationColumnarDataset(Dataset):\n\n    # オブジェクト定義\n    def __init__(self, df, target, cat_cols=CATEGORICAL):\n        self.df_cat = df[cat_cols]\n        self.df_num = df.drop(cat_cols, axis=1)\n        self.X_cats = self.df_cat.values.astype(np.int64)\n        self.X_nums = self.df_num.values.astype(np.float32)\n        self.target = target.values.astype(np.int64)\n\n    # データセットのサイズを返す\n    def __len__(self):\n        return len(self.target)\n\n    # 指定したインデックスのデータとラベルを返す\n    def __getitem__(self, idx):\n        return [self.X_cats[idx], self.X_nums[idx], self.target[idx]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:47:49.790927Z","iopub.execute_input":"2025-08-17T05:47:49.791230Z","iopub.status.idle":"2025-08-17T05:47:49.797814Z","shell.execute_reply.started":"2025-08-17T05:47:49.791208Z","shell.execute_reply":"2025-08-17T05:47:49.796817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# データセット作成\ntrain_dataset = ClassificationColumnarDataset(X_train, y_train)\nval_dataset = ClassificationColumnarDataset(X_val, y_val)\ntest_dataset = ClassificationColumnarDataset(df_test, pd.Series(np.zeros(len(df_test)).astype(np.int64)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:47:56.322603Z","iopub.execute_input":"2025-08-17T05:47:56.322859Z","iopub.status.idle":"2025-08-17T05:47:56.425856Z","shell.execute_reply.started":"2025-08-17T05:47:56.322843Z","shell.execute_reply":"2025-08-17T05:47:56.424665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# データローダー作成\ntrain_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:48:55.788467Z","iopub.execute_input":"2025-08-17T05:48:55.788722Z","iopub.status.idle":"2025-08-17T05:48:55.794209Z","shell.execute_reply.started":"2025-08-17T05:48:55.788705Z","shell.execute_reply":"2025-08-17T05:48:55.793165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# NNモデル作成\nclass TabularModel(nn.Module):\n\n    # ネットワーク構造の定義\n    def __init__(self, embedding_sizes, n_num):\n        super().__init__()\n        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories, size in embedding_sizes])\n        n_emb = sum(e.embedding_dim for e in self.embeddings)\n        self.n_emb, self.n_num = n_emb, n_num\n        self.lin1 = nn.Linear(self.n_emb + self.n_num, 100)\n        self.lin2 = nn.Linear(100, 70)\n        self.lin3 = nn.Linear(70, 2)\n        self.bn1 = nn.BatchNorm1d(self.n_num)\n        self.bn2 = nn.BatchNorm1d(100)\n        self.bn3 = nn.BatchNorm1d(70)\n        self.emb_drop = nn.Dropout(0.6)\n        self.drops = nn.Dropout(0.3)\n \n    # 順伝播\n    def forward(self,x_cat,x_num):\n        x = [e(x_cat[:, i]) for i, e in enumerate(self.embeddings)]\n        x = torch.cat(x, dim=1)\n        x = self.emb_drop(x)\n        x2 = self.bn1(x_num)\n        x = torch.cat([x, x2], dim=1)\n        x = F.relu(self.lin1(x))\n        x = self.drops(x)\n        x = self.bn2(x)\n        x = F.relu(self.lin2(x))\n        x = self.drops(x)\n        x = self.bn3(x)\n        x = self.lin3(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:49:01.752609Z","iopub.execute_input":"2025-08-17T05:49:01.752900Z","iopub.status.idle":"2025-08-17T05:49:01.761194Z","shell.execute_reply.started":"2025-08-17T05:49:01.752877Z","shell.execute_reply":"2025-08-17T05:49:01.760333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# インスタンス化\nmodel = TabularModel(emb_szs, len(num_col)).to(device)\n\n# 最適化手法の選択\noptimizer = torch.optim.Adam(model.parameters(),\n                            lr=0.001,\n                            betas=(0.9, 0.999),\n                            amsgrad=True)\n\n# 目的関数\ncompute_loss = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:49:06.847170Z","iopub.execute_input":"2025-08-17T05:49:06.847510Z","iopub.status.idle":"2025-08-17T05:49:06.857324Z","shell.execute_reply.started":"2025-08-17T05:49:06.847490Z","shell.execute_reply":"2025-08-17T05:49:06.856321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nhist = {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': []}\nEPOCHS = 10\nfor epoch in range(EPOCHS):\n    # 学習\n    train_loss = 0.\n    train_acc = 0.\n    all_labels_train = []\n    all_preds_train = []\n\n    model.train()\n    train_progress = tqdm(train_dataloader, total=len(train_dataloader), leave=False)\n    for batch_idx, (cat_data, num_data, target) in enumerate(train_progress):\n        train_progress.set_description(f'<Train> Epoch{epoch+1}')\n        cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(cat_data, num_data)\n        loss = compute_loss(output, target)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        train_acc += accuracy_score(target.tolist(), output.argmax(dim=-1).tolist())\n        all_labels_train += target.tolist()\n        all_preds_train += output.tolist()\n\n        train_progress.set_postfix(loss=train_loss/(batch_idx+1), acc=train_acc/(batch_idx+1))\n\n    train_loss /= len(train_dataloader)\n    train_acc /= len(train_dataloader)\n\n    # 検証\n    val_loss = 0.\n    val_acc = 0.\n    best_acc = 0.\n    all_labels_val = []\n    all_preds_val = []    \n\n    model.eval()\n    val_progress = tqdm(val_dataloader, total=len(val_dataloader), leave=False)\n    with torch.no_grad():\n        for batch_idx, (cat_data, num_data, target) in enumerate(val_progress):\n            val_progress.set_description(f'<Val> Epoch{epoch+1}')\n            cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n            output = model(cat_data, num_data)\n            loss = compute_loss(output, target)\n\n            val_loss += loss.item()\n            val_acc += accuracy_score(target.tolist(), output.argmax(dim=-1).tolist())\n            all_labels_val += target.tolist()\n            all_preds_val += output.tolist()\n\n            val_progress.set_postfix(loss=val_loss/(batch_idx+1), acc=val_acc/(batch_idx+1))\n        \n        val_loss /= len(val_dataloader)\n        val_acc /= len(val_dataloader)\n\n    # modelの保存\n    # if val_acc > best_acc:\n    #     best_acc = val_acc\n    #     torch.save(model.state_dict(), MODELS_DIR + f'best_NN_0.pth')\n\n\n    # 学習状況を保存\n    hist['train_loss'].append(train_loss)\n    hist['train_accuracy'].append(train_acc)\n    hist['val_loss'].append(val_loss)\n    hist['val_accuracy'].append(val_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T06:23:13.880107Z","iopub.execute_input":"2025-08-17T06:23:13.880566Z","iopub.status.idle":"2025-08-17T06:27:33.106217Z","shell.execute_reply.started":"2025-08-17T06:23:13.880517Z","shell.execute_reply":"2025-08-17T06:27:33.104408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 検証データの誤差の可視化\ntrain_loss = hist['train_loss']\nval_loss = hist['val_loss']\n\nfig = plt.figure()\nplt.rc('font', family='serif')\nplt.plot(range(len(train_loss)), train_loss, linewidth=1, label='train_loss')\nplt.plot(range(len(val_loss)), val_loss, color='red', linewidth=1, label='val_loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T06:27:33.108004Z","iopub.execute_input":"2025-08-17T06:27:33.108723Z","iopub.status.idle":"2025-08-17T06:27:33.277372Z","shell.execute_reply.started":"2025-08-17T06:27:33.108698Z","shell.execute_reply":"2025-08-17T06:27:33.275948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'validation data best acc : {best_acc}')\n\n# 検証データの精度の可視化\ntrain_acc = hist['train_accuracy']\nval_acc = hist['val_accuracy']\n\nfig = plt.figure()\nplt.rc('font', family='serif')\nplt.plot(range(len(train_acc)), train_acc, linewidth=1, label='train_acc')\nplt.plot(range(len(val_acc)), val_acc, color='red', linewidth=1, label='val_acc')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T06:27:33.278326Z","iopub.execute_input":"2025-08-17T06:27:33.278595Z","iopub.status.idle":"2025-08-17T06:27:33.442411Z","shell.execute_reply.started":"2025-08-17T06:27:33.278576Z","shell.execute_reply":"2025-08-17T06:27:33.441350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n\n# # 数値列の標準化\n# scaler = StandardScaler()\n# std_train = scaler.fit_transform(X_train[num_col])\n# std_valid = scaler.fit_transform(X_valid[num_col])\n# # std_test = scaler.transform(test_df[num_col])\n\n# # データフレームに変換\n# std_train_df = pd.DataFrame(std_train,columns=num_col)\n# std_valid_df = pd.DataFrame(std_valid,columns=num_col)\n# # std_test_df = pd.DataFrame(scaled_test,columns=num_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:36:58.892417Z","iopub.execute_input":"2025-08-16T13:36:58.892730Z","iopub.status.idle":"2025-08-16T13:36:59.158049Z","shell.execute_reply.started":"2025-08-16T13:36:58.892705Z","shell.execute_reply":"2025-08-16T13:36:59.156844Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # One-Hotエンコード(カテゴリデータ)\n# from sklearn.preprocessing import OneHotEncoder\n\n# OHE = OneHotEncoder(sparse_output=False,dtype=int,handle_unknown=\"ignore\")\n\n# # 訓練データでfit\n# OHE.fit(X_train[cat_col])\n\n# # 訓練・テストに対してtransform\n# OHE_train = OHE.transform(X_train[cat_col])\n# OHE_valid = OHE.transform(X_valid[cat_col])\n\n# # カラム取得\n# OHE_col = OHE.get_feature_names_out(cat_col)\n\n# # データフレーム変換\n# OHE_train_df = pd.DataFrame(\n#     OHE_train, columns=OHE.get_feature_names_out(cat_col))\n# OHE_valid_df = pd.DataFrame(\n#     OHE_valid, columns=OHE.get_feature_names_out(cat_col))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:36:59.161899Z","iopub.execute_input":"2025-08-16T13:36:59.162187Z","iopub.status.idle":"2025-08-16T13:37:03.060550Z","shell.execute_reply.started":"2025-08-16T13:36:59.162165Z","shell.execute_reply":"2025-08-16T13:37:03.059655Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 訓練データの結合\n# com_train_df = pd.concat([std_train_df,OHE_train_df],axis=1)\n# y_train_df = pd.DataFrame(y_train,columns=[\"y\"])\n\n# com_valid_df = pd.concat([std_valid_df,OHE_valid_df],axis=1)\n# y_valid_df = pd.DataFrame(y_valid,columns=[\"y\"])\n# com_train_df = pd.concat([std_train_df,OHE_train_df,\n#                           pd.DataFrame(y_train,columns=[\"y\"])],axis=1)\n# com_valid_df = pd.concat([std_valid_df,OHE_valid_df,\n#                           pd.DataFrame(y_valid,columns=[\"y\"])],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:37:36.621511Z","iopub.execute_input":"2025-08-16T13:37:36.621861Z","iopub.status.idle":"2025-08-16T13:37:37.810695Z","shell.execute_reply.started":"2025-08-16T13:37:36.621830Z","shell.execute_reply":"2025-08-16T13:37:37.809679Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# std_train_tensor = torch.tensor(std_train_df.values,\n#                                   dtype=torch.float32)\n# std_valid_tensor = torch.tensor(std_valid_df.values,\n#                                   dtype=torch.float32)\n# OHE_train_tensor = torch.tensor(OHE_train_df.values,\n#                                   dtype=torch.long)\n# OHE_valid_tensor = torch.tensor(OHE_valid_df.values,\n#                                   dtype=torch.long)\n# lb_train_tensor = torch.tensor(y_train.values,\n#                                   dtype=torch.float32)\n# lb_valid_tensor = torch.tensor(y_valid.values,\n#                                   dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:37:03.061759Z","iopub.execute_input":"2025-08-16T13:37:03.062038Z","iopub.status.idle":"2025-08-16T13:37:03.405542Z","shell.execute_reply.started":"2025-08-16T13:37:03.062010Z","shell.execute_reply":"2025-08-16T13:37:03.404532Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Embeddingは次回にする\n# from sklearn.preprocessing import LabelEncoder\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# # ラベルエンコード\n# for col in cat_col:\n#     le = LabelEncoder()\n#     all_df[col] = le.fit_transform(all_df[col].values)\n\n#     # Tensor化\n#     all_df[col] = torch.tensor(all_df[col],dtype=torch.long)\n\n#     # Embedding層に入力\n#     num_class = len(le.classes_)\n#     embedding_dim = 3 # 埋め込みベクトルの次元数","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Datasetクラスの定義\nfrom torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n    def __init__(self,num_tensor,cat_tensor,label_tensor):\n        self.num = num_tensor\n        self.cat = cat_tensor\n        self.label = label_tensor\n\n    # データセットのサイズを返す\n    def __len__(self):\n        return len(self.label)\n\n    # 指定したインデックスのデータとラベルを返す\n    def __getitem__(self, idx):\n        return self.num[idx],self.cat[idx],self.label[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:40:20.856757Z","iopub.execute_input":"2025-08-16T13:40:20.857142Z","iopub.status.idle":"2025-08-16T13:40:20.863635Z","shell.execute_reply.started":"2025-08-16T13:40:20.857113Z","shell.execute_reply":"2025-08-16T13:40:20.862392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DataLoader作成\nfrom torch.utils.data import DataLoader\n\n# バッチサイズ\nbs = 8\n\nfeature_cols = com_train_df.columns\ntarget_col = \"y\"\n\n# データセット\ntrain_dataset = CustomDataset(\n    std_train_tensor,OHE_train_tensor,lb_train_tensor)\n                              \nvalid_dataset = CustomDataset(\n    std_valid_tensor,OHE_valid_tensor,lb_valid_tensor)\n\n# データローダー\ntrain_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:42:44.605841Z","iopub.execute_input":"2025-08-16T13:42:44.606170Z","iopub.status.idle":"2025-08-16T13:42:44.632217Z","shell.execute_reply.started":"2025-08-16T13:42:44.606145Z","shell.execute_reply":"2025-08-16T13:42:44.631222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# NNモデル作成\nclass NeuralNet(nn.Module):\n\n    # 使用するオブジェクトを定義\n    def __init__(self,\n                 num_num_features,\n                 num_categories,\n                 embedding_dim=4):\n        super(NeuralNet, self).__init__()\n        self.num_layer = nn.Linear(num_num_features,8) # 数値特徴処理\n        self.emb_layer = nn.Embedding(num_categories,embedding_dim) # カテゴリ特徴処理\n        self.fc = nn.Linear(8+embedding_dim,1)\n\n    # 順伝播\n    def forward(self,num_x,cat_x):\n        num_out = torch.relu(self.num_layer(num_x))\n        cat_out = self.emb_layer(cat_x).squeeze(1)\n        x = torch.cat([num_out,cat_out],dim=1)\n        return torch.sigmoid(self.fc(x))\n\n# インスタンス化\nmodel = NeuralNet(num_num_features=7,\n                  num_categories=44)\n\n# 最適化手法\nlr = 1e-3\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\n# 損失関数\ncriterion = nn.BCELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:58:38.673368Z","iopub.execute_input":"2025-08-16T13:58:38.673707Z","iopub.status.idle":"2025-08-16T13:58:38.683339Z","shell.execute_reply.started":"2025-08-16T13:58:38.673681Z","shell.execute_reply":"2025-08-16T13:58:38.682084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# エポックの数\nmax_epoch = 5\n\n# モデルの初期化\ntorch.manual_seed(42)\n\n# 訓練データ結果\n# 検証データ結果\n\n# 学習ループ\nfor epoch in range(max_epoch):\n\n    # 訓練モード\n    model.train()\n    \n    for batch_num,batch_cat,batch_label in train_loader:\n\n        # パラメータの勾配を初期化\n        optimizer.zero_grad() \n\n        # 入力データとラベルをGPU用に変換\n        # x = x.to(device)\n        # t = t.to(device)\n        \n        # 順伝播 (batch_size,1 -> (batch_size,))\n        preds = model(batch_num,batch_cat).squeeze()\n\n        # ロス計算\n        loss = criterion(preds,batch_label)\n\n        # 各パラメータの勾配を算出\n        loss.backward()   \n        \n        # パラメータ更新    \n        optimizer.step()   \n\n    # 評価モード\n    model.eval()\n\n    # 訓練データの計算\n    tmp_xtrain = x_train_tensor.to(device)\n    tmp_ytrain = y_train_tensor.to(device)    \n    # valデータの計算\n    tmp_xvalid = x_valid_tensor.to(device)\n    tmp_yvalid = y_valid_tensor.to(device)  \n\n    # 予測\n    y1 = model(tmp_xtrain)\n    loss1 = criterion(y1,tmp_ytrain)\n\n    y2 = model(tmp_xvalid)\n    loss2 = criterion(y2,tmp_yvalid)\n\n    # 最大値を抽出\n    y_pred1 = torch.argmax(y1,1)\n    y_pred2 = torch.argmax(y2,1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:58:38.932850Z","iopub.execute_input":"2025-08-16T13:58:38.933133Z","iopub.status.idle":"2025-08-16T13:58:39.016686Z","shell.execute_reply.started":"2025-08-16T13:58:38.933114Z","shell.execute_reply":"2025-08-16T13:58:39.015566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}