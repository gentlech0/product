{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ライブラリのインポート\nimport numpy as np\nimport pandas as pd\nimport os\n\n# データフレーム読み込み\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\n\n# データ結合\nall_df = pd.concat([train_df,test_df],axis=0,ignore_index=True)\nall_df_NN = all_df.copy()\nmax_row = len(all_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:51:56.185344Z","iopub.execute_input":"2025-08-30T05:51:56.185675Z","iopub.status.idle":"2025-08-30T05:51:58.857504Z","shell.execute_reply.started":"2025-08-30T05:51:56.185650Z","shell.execute_reply":"2025-08-30T05:51:58.856585Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# all_df.info() # 特徴量、欠損、型確認","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# all_df.head(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 数値列のカテゴリ化を行う","metadata":{}},{"cell_type":"markdown","source":"### 新規特徴量を作成する","metadata":{}},{"cell_type":"code","source":"# (1) 住宅ローン + ローン\nall_df[\"housing_loan\"] = all_df[\"housing\"].astype(str) + \"_\" + all_df[\"loan\"].astype(str)\n\n# (2) コンタクト時間 x 年齢\nall_df[\"duration_x_age\"] = all_df[\"duration\"] * all_df[\"age\"]\n\n# (3) sin,cos(コンタクト時間)\nall_df['duration_sin'] = np.sin(2*np.pi * all_df['duration'] / 400)\nall_df['duration_cos'] = np.cos(2*np.pi * all_df['duration'] / 400)\n\n# (4) monthを数値に直し周期的に使う\nmonth_map = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4,\n    'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n    'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\nall_df['month_num'] = all_df['month'].map(month_map).astype('int')\nall_df['month_sin'] = np.sin(2 * np.pi * all_df['month_num'] / 12)\nall_df['month_cos'] = np.cos(2 * np.pi * all_df['month_num'] / 12)\n\n# (5) コンタクト時間をカテゴリ化\nall_df['duration_bin'] = pd.cut(\n    all_df['duration'],\n    bins=[0, 60, 300, 600, 900, float('inf')],\n    labels=['short', 'medium', 'long', 'very_long', 'extreme'],\n    right=False)\nall_df['duration_bin'] = all_df['duration_bin'].astype(\"object\")\n\n# (6) 連絡手段 + 年齢\nall_df['age_group'] = pd.cut(\n    all_df['age'],\n    bins=[0, 30, 45, 60, 100],\n    labels=['young', 'mid', 'senior', 'elder'])\nall_df[\"contact_age\"] = all_df[\"contact\"].astype(str) + \"_\" + all_df[\"age_group\"].astype(str)\nall_df = all_df.drop(\"age_group\",axis=1)\n\n# (7) sin,cos(pdays)\nall_df['pdays_sin'] = np.sin(2*np.pi * all_df['pdays'] / 90)\nall_df['pdays_cos'] = np.cos(2*np.pi * all_df['pdays'] / 90)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:51:58.858895Z","iopub.execute_input":"2025-08-30T05:51:58.859226Z","iopub.status.idle":"2025-08-30T05:51:59.858116Z","shell.execute_reply.started":"2025-08-30T05:51:58.859196Z","shell.execute_reply":"2025-08-30T05:51:59.857288Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# dayが5-10日はy=0が多い\n# all_df[\"day_cls\"] = all_df[\"day\"].copy()\n# all_df.loc[all_df[\"day\"]%10<5,\"day_cls\"] = \"1stHalf\"\n# all_df.loc[all_df[\"day\"]%10>=5,\"day_cls\"] = \"2ndHalf\"\n# all_df[\"day_cls\"] = all_df[\"day_cls\"].astype(str)\n\n# sin,cos(10days)\n# all_df['days_sin/5'] = np.sin(2*np.pi * all_df['day'] / 5)\n# all_df['days_cos/5'] = np.cos(2*np.pi * all_df['day'] / 5)\n\n# sin,cos(15days)\n# all_df['days_sin/15'] = np.sin(2*np.pi * all_df['pdays'] / 15)\n# all_df['days_cos/15'] = np.cos(2*np.pi * all_df['pdays'] / 15)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### カテゴリ化した元は数値の列を削除する","metadata":{}},{"cell_type":"code","source":"# # カテゴリ列削除\n# RMV = [\"age_cls\",\"balance_cls\",\"duration_cls\",\"campaign_cls\",\"pdays_cls\",\"previous_cls\"]\n# all_df = all_df.drop(RMV,axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 数値列とカテゴリ列を取得\nnum_col = []\ncat_col = []\n\n# train_df = train_df.drop([\"id\",\"y\"],axis=1)\n\nall_df2 = all_df.drop([\"id\",\"y\"],axis=1)\n\nfor col in all_df2.columns:\n    if all_df2[col].dtypes!=\"object\":\n        num_col.append(col)\n    else:\n        cat_col.append(col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:52:00.635236Z","iopub.execute_input":"2025-08-30T05:52:00.635515Z","iopub.status.idle":"2025-08-30T05:52:00.802489Z","shell.execute_reply.started":"2025-08-30T05:52:00.635496Z","shell.execute_reply":"2025-08-30T05:52:00.801831Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"all_df[cat_col] = all_df[cat_col].astype(\"category\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:52:32.490664Z","iopub.execute_input":"2025-08-30T05:52:32.490937Z","iopub.status.idle":"2025-08-30T05:52:33.279365Z","shell.execute_reply.started":"2025-08-30T05:52:32.490917Z","shell.execute_reply":"2025-08-30T05:52:33.278486Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# 訓練データとテストデータに分離\ntrain = all_df[:len(train_df)]\ntest = all_df[len(train_df):]\n\n# 訓練データをx,yに分割\nX_train = train.drop([\"id\",\"y\"],axis=1)\ny_train = train[\"y\"]\nX_test = test.drop([\"id\",\"y\"],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:52:34.979546Z","iopub.execute_input":"2025-08-30T05:52:34.979888Z","iopub.status.idle":"2025-08-30T05:52:35.077043Z","shell.execute_reply.started":"2025-08-30T05:52:34.979860Z","shell.execute_reply":"2025-08-30T05:52:35.076211Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# # 相関係数を確認する\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n\n# train_corr = X_train.drop(cat_col,axis=1).corr()\n# sns.clustermap(train_corr,annot=True,fmt=\".2f\",cmap=\"bwr\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.preprocessing import LabelEncoder\n\n# # 辞書にLabelEncoderを保持\n# label_encoders = {}\n\n# # カテゴリ列だけエンコード\n# X_train_cat = pd.DataFrame()\n# X_test_cat = pd.DataFrame()\n\n# for col in cat_col:\n#     le = LabelEncoder()\n#     le.fit(X_train[col])\n\n#     X_train_cat[col] = le.transform(X_train[col])\n#     X_test_cat[col] = le.transform(X_test[col])\n\n#     label_encoders[col] = le\n\n# # 数値列はそのままコピー\n# X_train_num = X_train[num_col].copy()\n# X_train_num = X_train_num.reset_index()\n# X_test_num = X_test[num_col].copy()\n# X_test_num = X_test_num.reset_index()\n\n# # 最後に結合（カテゴリ + 数値）\n# X_train_enc = pd.concat([X_train_num, X_train_cat], axis=1)\n# X_test_enc  = pd.concat([X_test_num, X_test_cat], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T01:01:20.713143Z","iopub.execute_input":"2025-08-30T01:01:20.713565Z","iopub.status.idle":"2025-08-30T01:01:23.486993Z","shell.execute_reply.started":"2025-08-30T01:01:20.713533Z","shell.execute_reply":"2025-08-30T01:01:23.486125Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### 【Light GBM + Optuna】","metadata":{}},{"cell_type":"code","source":"# ###################################################\n# ############ Light GBM + Optuna####################\n# ###################################################\n# import optuna\n# import lightgbm as lgb\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import StratifiedKFold\n# from sklearn.metrics import roc_auc_score\n\n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# # 入力データ\n# X = X_train\n# y = y_train\n\n# def objective(trial):\n\n#     # パラメータ\n#     lgbm_params = {\n#         'objective': 'binary',\n#         # \"device\": \"cpu\",\n#         \"device\": \"gpu\",\n#         'metric': 'auc',\n#         'verbose': -1,              # ログ出力の制御\n#         'boosting_type': 'gbdt',\n#         'learning_rate': 0.1,\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n#         'num_leaves': trial.suggest_int('num_leaves', 16, 256),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n#         'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0,log=True),\n#         'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0,log=True),\n#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n#         }\n    \n#     oof_lgb = np.zeros(len(X))\n#     fold_scores = []\n\n#     # クロスバリデーション\n#     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    \n#     # for fold,(train_idx,valid_idx) in enumerate(kf.split(X)):\n#     for fold,(train_idx,valid_idx) in enumerate(skf.split(X,y)):\n\n#         print(\"#\"*25)\n#         print(f\"### Fold {fold+1}\")\n#         print(\"#\"*25)\n\n    \n#         X_train_kf = X.iloc[train_idx,:]\n#         y_train_kf = y.iloc[train_idx]\n#         X_valid_kf = X.iloc[valid_idx,:]\n#         y_valid_kf = y.iloc[valid_idx]\n    \n#         # データセット作成\n#         lgb_train_lgb = lgb.Dataset(X_train_kf,y_train_kf,\n#                                     categorical_feature=cat_col)\n#         lgb_valid_lgb = lgb.Dataset(X_valid_kf,y_valid_kf,\n#                                     categorical_feature=cat_col)\n\n#         # 学習\n#         model_lgb = lgb.train(\n#             lgbm_params,\n#             lgb_train_lgb,\n#             num_boost_round=1000,\n#             valid_sets=[lgb_train_lgb,lgb_valid_lgb],\n#             valid_names=[\"train\",\"valid\"],\n#             callbacks=[\n#                 lgb.early_stopping(stopping_rounds=50,verbose=False),\n#                 lgb.log_evaluation(100),])\n    \n#         # 各foldでのバリデーション予測\n#         oof_lgb[valid_idx] = model_lgb.predict(\n#             X_valid_kf, num_iteration=model_lgb.best_iteration)\n\n#         # AUCスコア算出\n#         fold_scores.append(roc_auc_score(y_valid_kf,oof_lgb[valid_idx]))\n\n#     score = np.mean(fold_scores)\n\n#     return score\n    \n# study = optuna.create_study(direction=\"maximize\",\n#                            pruner=optuna.pruners.MedianPruner())\n# study.optimize(objective, n_trials=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:48:14.690436Z","iopub.execute_input":"2025-08-28T14:48:14.690722Z","iopub.status.idle":"2025-08-28T14:48:14.69631Z","shell.execute_reply.started":"2025-08-28T14:48:14.690701Z","shell.execute_reply":"2025-08-28T14:48:14.695418Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for i, trial in enumerate(study.best_trials):\n#   print(trial.params)\n#   print([j for j in trial.values])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T13:59:22.307427Z","iopub.execute_input":"2025-08-25T13:59:22.307983Z","iopub.status.idle":"2025-08-25T13:59:22.312879Z","shell.execute_reply.started":"2025-08-25T13:59:22.307954Z","shell.execute_reply":"2025-08-25T13:59:22.312011Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(study.best_trial)\n# print(study.best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T13:59:32.276139Z","iopub.execute_input":"2025-08-25T13:59:32.276692Z","iopub.status.idle":"2025-08-25T13:59:32.28076Z","shell.execute_reply.started":"2025-08-25T13:59:32.276668Z","shell.execute_reply":"2025-08-25T13:59:32.280165Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# best_params = study.best_params\n\n# best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T14:00:02.924588Z","iopub.execute_input":"2025-08-25T14:00:02.924874Z","iopub.status.idle":"2025-08-25T14:00:02.930187Z","shell.execute_reply.started":"2025-08-25T14:00:02.924853Z","shell.execute_reply":"2025-08-25T14:00:02.929658Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【Light GBM】","metadata":{}},{"cell_type":"code","source":"###################################################\n############ Light GBM (with TE) ##################\n###################################################\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport warnings\nimport traceback\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# --- データ準備 ---\nX_train_te = X_train.copy()  # 元のカテゴリ列は残す\nX_test_te = X_test.copy()\ny = y_train\ncat_cols = cat_col  # カテゴリ列の名前リスト\nn_splits = 5\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# --- ターゲットエンコーディング列を初期化 ---\nfor col in cat_cols:\n    X_train_te[col + \"_te\"] = 0.0\n    X_test_te[col + \"_te\"] = 0.0\n\n# --- ターゲットエンコーディング ---\nfor col in cat_cols:\n    for train_idx, valid_idx in skf.split(X_train_te, y):\n        X_tr, X_val = X_train_te.iloc[train_idx], X_train_te.iloc[valid_idx]\n        y_tr = y.iloc[train_idx]\n\n        mapping = X_tr.groupby(col)[y_tr.name].mean()\n        X_train_te.iloc[valid_idx, X_train_te.columns.get_loc(col + \"_te\")] = \\\n            X_val[col].map(mapping).fillna(y_tr.mean()).astype(float)\n\n    full_mapping = X_train_te.groupby(col)[y.name].mean()\n    X_test_te[col + \"_te\"] = X_test_te[col].map(full_mapping).fillna(y.mean()).astype(float)\n\n# --- LightGBM 学習設定 ---\npred_lgb = np.zeros(len(X_train_te))\npred_lgb_test = np.zeros(len(X_test_te))\nmodels_lgb = []\nevals_result_lgb = {}\n\nlgbm_params = {\n    'objective': 'binary',\n    \"device\": \"gpu\",\n    'metric': 'auc',\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.03,\n    'num_leaves': 63,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'min_data_in_leaf': 100,\n    'lambda_l1': 1e-3,\n    'lambda_l2': 1e-2,\n    'max_bin': 255,\n    'verbosity': -1\n}\n\n# --- クロスバリデーション ---\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(X_train_te, y)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {fold+1}\")\n    print(\"#\"*25)\n\n    X_tr, y_tr = X_train_te.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X_train_te.iloc[valid_idx], y.iloc[valid_idx]\n\n    # 学習用 Dataset\n    lgb_train_lgb = lgb.Dataset(X_tr, y_tr)\n    lgb_valid_lgb = lgb.Dataset(X_val, y_val)\n\n    model_lgb = lgb.train(\n        lgbm_params,\n        lgb_train_lgb,\n        num_boost_round=2000,\n        valid_sets=[lgb_train_lgb, lgb_valid_lgb],\n        valid_names=[\"train\", \"valid\"],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=100, verbose=False),\n            lgb.record_evaluation(evals_result_lgb),\n            lgb.log_evaluation(100)\n        ]\n    )\n\n    # バリデーション予測\n    pred_lgb[valid_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\n    \n    # モデル保存\n    models_lgb.append(model_lgb)\n\n    # テスト予測\n    pred_lgb_test += model_lgb.predict(X_test_te, num_iteration=model_lgb.best_iteration)\n\n# --- テスト予測を平均 ---\npred_lgb_test /= n_splits\n\n# --- OOFスコア確認 ---\noof_auc = roc_auc_score(y, pred_lgb)\nprint(f\"OOF AUC: {oof_auc:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:58:28.682933Z","iopub.execute_input":"2025-08-30T06:58:28.683731Z","iopub.status.idle":"2025-08-30T06:58:29.203086Z","shell.execute_reply.started":"2025-08-30T06:58:28.683698Z","shell.execute_reply":"2025-08-30T06:58:29.202121Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1999334330.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mX_train_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_te\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1949\u001b[0m                 \u001b[0;34m\"Use a list instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m             )\n\u001b[0;32m-> 1951\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Column not found: y'"],"ename":"KeyError","evalue":"'Column not found: y'","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"# 訓練データのスコア\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n\nAUC_lgb = roc_auc_score(y,pred_lgb)\nF1_lgb = f1_score(y,np.round(pred_lgb,0))\nprint(f\"LGB: AUC score = {AUC_lgb}, F1 = {F1_lgb}\")\n\n# 学習曲線\n# lgb.plot_metric(evals_result_lgb,title=\"LightGBM AUC\",)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T01:05:49.462072Z","iopub.execute_input":"2025-08-30T01:05:49.463036Z","iopub.status.idle":"2025-08-30T01:05:50.380311Z","shell.execute_reply.started":"2025-08-30T01:05:49.462987Z","shell.execute_reply":"2025-08-30T01:05:50.379259Z"}},"outputs":[{"name":"stdout","text":"LGB: AUC score = 0.9707393848061008, F1 = 0.7398322546942566\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# import shap\n# import lightgbm as lgb\n# import matplotlib.pyplot as plt\n# shap.initjs()\n\n# # サンプリング\n# X_sample = X.sample(2000, random_state=0)\n\n# shapval = 0\n# for i in range(5):\n#     explainer = shap.TreeExplainer(models_lgb[i])\n#     shap_values = explainer.shap_values(X_sample)\n#     if isinstance(shap_values, list):  # 2クラス分類\n#         shap_values = shap_values[1]\n#     shapval += shap_values\n\n# shap.summary_plot(shapval, X_sample, plot_type=\"bar\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 重要度の算出\n# feature_importances = 0\n# for i in range(5):\n#   feature_importances += pd.DataFrame(models_lgb[i].feature_importance(),columns=['importance'])\n\n# feature=pd.DataFrame(X.columns,columns=['feature'])\n# o=pd.concat([feature,feature_importances],axis=1)\n# o = o.sort_values(\"importance\", ascending=False)\n# print(o)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# plt.figure(figsize=(16, 16))\n# sns.barplot(data=o.sort_values(by='importance', ascending=False), x='importance', y='feature')\n# plt.title('Feature Importances ')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = pred_lgb_test\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【XGBoost + Optuna】","metadata":{}},{"cell_type":"code","source":"# #################################################\n# ############ XGBoost ############################\n# #################################################\n# import optuna\n# import xgboost as xgb\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import StratifiedKFold\n# from sklearn.metrics import roc_auc_score\n\n# # 学習、バリデーションデータ\n# pred_xgb = np.zeros(len(train_df))\n# pred_xgb_test = np.zeros(len(test_df))\n# models_xgb = []\n\n# # 入力データ\n# X = X_train\n# y = y_train\n\n# # --- fold ごとに DMatrix を事前作成 ---\n# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# dtrain_folds = []\n# dvalid_folds = []\n\n# for train_idx, valid_idx in skf.split(X, y):\n#     X_train_kf, X_valid_kf = X.iloc[train_idx], X.iloc[valid_idx]\n#     y_train_kf, y_valid_kf = y.iloc[train_idx], y.iloc[valid_idx]\n\n#     dtrain = xgb.DMatrix(X_train_kf, label=y_train_kf, enable_categorical=True)\n#     dvalid = xgb.DMatrix(X_valid_kf, label=y_valid_kf, enable_categorical=True)\n\n#     dtrain_folds.append(dtrain)\n#     dvalid_folds.append(dvalid)\n\n# # --- Optuna objective ---\n# def objective(trial):\n#     params = {\n#         \"objective\": \"binary:logistic\",\n#         \"tree_method\": \"hist\",  # GPU 用\n#         \"device\": \"cuda\",\n#         \"eval_metric\": \"auc\",\n#         \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n#         \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 10.0, log=True),\n#         \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 10.0, log=True),\n#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 1.0),\n#         \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n#         \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n#         \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 10.0, log=True),\n#         \"learning_rate\": 0.1\n#     }\n\n#     scores = []\n\n#     # trial 内では DMatrix を再利用\n#     for dtrain, dvalid in zip(dtrain_folds, dvalid_folds):\n#         model = xgb.train(\n#             params,\n#             dtrain,\n#             num_boost_round=1000,\n#             evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n#             early_stopping_rounds=50,\n#             verbose_eval=100\n#         )\n\n#         preds = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n#         scores.append(roc_auc_score(dvalid.get_label(), preds))\n\n#     return np.mean(scores)\n\n# # --- Optuna 実行 ---\n# study = optuna.create_study(direction=\"maximize\",\n#                            pruner=optuna.pruners.MedianPruner())\n# study.optimize(objective, n_trials=5)  # 仮チューニング用に少なめ\n\n# print(\"Best Score:\", study.best_value)\n# print(\"Best Params:\", study.best_params)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-26T14:00:50.293Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【XGBoost】","metadata":{}},{"cell_type":"code","source":"#################################################\n############ XGBoost ############################\n#################################################\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\n# 学習、バリデーションデータ\npred_xgb = np.zeros(len(train_df))\npred_xgb_test = np.zeros(len(test_df))\nmodels_xgb = []\n\n# 入力データ\nX = X_train_enc\ny = y_train\nX_test = X_test_enc\n\n\n# 評価履歴を保存する辞書\nevals_result_xgb = {}\n\n# パラメータ\nxgb_params = {\n    \"objective\": \"binary:logistic\",  \n    \"eval_metric\": \"auc\",           \n    \"learning_rate\": 0.1,\n    \"max_depth\": 0,\n    \"subsample\": 0.8,\n    \"colsample_bytree\": 0.7,\n    \"tree_method\": \"gpu_hist\",\n    \"gpu_id\": 0,\n    \"grow_policy\": \"lossguide\", \n    \"max_leaves\": 32,           \n    \"alpha\": 2.0,\n}\n\n# クロスバリデーション\n# kf = KFold(n_splits=5, shuffle=True, random_state=42)\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# for fold, (train_idx,valid_idx) in enumerate(kf.split(X)):\nfor fold,(train_idx,valid_idx) in enumerate(skf.split(X,y)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {fold+1}\")\n    print(\"#\"*25)\n\n    # foldごとの訓練、バリデーションデータ\n    X_train_kf = X.iloc[train_idx,:]\n    y_train_kf = y.iloc[train_idx]\n    X_valid_kf = X.iloc[valid_idx,:]\n    y_valid_kf = y.iloc[valid_idx]\n\n    # DMatrixに変換\n    dtrain = xgb.DMatrix(X_train_kf,label=y_train_kf,enable_categorical=True)\n    dvalid = xgb.DMatrix(X_valid_kf,label=y_valid_kf,enable_categorical=True)\n\n    # 学習\n    model_xgb = xgb.train(\n        xgb_params,\n        dtrain,\n        num_boost_round=2000,\n        evals=[(dtrain,\"train\"),(dvalid,\"valid\")],\n        early_stopping_rounds=100,\n        evals_result=evals_result_xgb,\n        verbose_eval=100,\n    )\n\n    # 各foldでのバリデーション予測\n    pred_xgb[valid_idx] = model_xgb.predict(\n        dvalid,\n        iteration_range=(0,model_xgb.best_iteration+1))\n\n    # モデルの追加\n    models_xgb.append(model_xgb)\n\n    # テストの予測\n    dtest = xgb.DMatrix(X_test,enable_categorical=True)\n    pred_xgb_test = pred_xgb_test + model_xgb.predict(\n        dtest,\n        iteration_range=(0,model_xgb.best_iteration+1))\n\n# FOLD数で割る\npred_xgb_test = pred_xgb_test/5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:41:42.161516Z","iopub.execute_input":"2025-08-29T14:41:42.162049Z","iopub.status.idle":"2025-08-29T14:41:45.795735Z","shell.execute_reply.started":"2025-08-29T14:41:42.162028Z","shell.execute_reply":"2025-08-29T14:41:45.795136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 訓練データのスコア\nfrom sklearn.metrics import f1_score\n\nAUC_xgb = roc_auc_score(y,pred_xgb)\nF1_xgb = f1_score(y,np.round(pred_xgb,0))\nprint(f\"XGB: AUC score = {AUC_xgb}, F1 = {F1_xgb}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:44:34.235995Z","iopub.execute_input":"2025-08-29T14:44:34.23626Z","iopub.status.idle":"2025-08-29T14:44:35.086966Z","shell.execute_reply.started":"2025-08-29T14:44:34.236241Z","shell.execute_reply":"2025-08-29T14:44:35.086351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = pred_xgb_test\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 学習曲線の描画\n# from matplotlib.pyplot as plt\n# epochs = len(evals_result_xgb['train']['auc'])\n# x_axis = range(0, epochs)\n\n# plt.figure()\n# plt.plot(x_axis, evals_result_xgb['train']['auc'], label='Train')\n# plt.plot(x_axis, evals_result_xgb['valid']['auc'], label='Validation')\n# plt.xlabel('Iteration')\n# plt.ylabel('AUC')\n# plt.title('XGBoost AUC')\n# plt.grid()\n# plt.legend()\n# plt.show()","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【CatBoost + Optuna】","metadata":{}},{"cell_type":"code","source":"# #################################################\n# ############ CatBoost ############################\n# #################################################\n# # from catboost import Pool, train\n# from catboost import CatBoostClassifier, Pool\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import StratifiedKFold\n# import optuna\n# import numpy as np\n\n# # 入力データ\n# X = X_train\n# y = y_train\n\n# # 履歴を保存\n# cb_auc_valid = []\n\n\n# def objective(trial):\n\n#     cat_params = {\n#         'iterations' : trial.suggest_int('iterations', 300, 2000),\n#         'depth' : trial.suggest_int('depth', 6, 10),\n#         'random_strength' :trial.suggest_int('random_strength', 1, 20),\n#         'bagging_temperature' :trial.suggest_float('bagging_temperature', 0.1, 10.0, log=True),\n#         'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n#         'od_wait' :trial.suggest_int('od_wait', 10, 50),\n#         'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n#         \"loss_function\": \"Logloss\",\n#         \"eval_metric\": \"AUC\",\n#         # \"task_type\": \"CPU\",\n#         # 'learning_rate' : 0.1,\n#         \"task_type\": \"GPU\",\n#         # \"devices\": \"0\",\n#         \"verbose\": False,\n#     }\n    \n#     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n#     scores = []\n    \n#     for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n#         print(f\"  >> Fold {fold+1}/{skf.n_splits} 開始\")\n#         X_train_kf, y_train_kf = X.iloc[train_idx].copy(), y.iloc[train_idx]\n#         X_valid_kf, y_valid_kf = X.iloc[valid_idx].copy(), y.iloc[valid_idx]\n\n#         # カテゴリ変換\n#         for col in cat_col:\n#             X_train_kf[col] = X_train_kf[col].astype(\"category\")\n#             X_valid_kf[col] = X_valid_kf[col].astype(\"category\")\n\n#         train_pool = Pool(X_train_kf, y_train_kf, cat_features=cat_col)\n#         valid_pool = Pool(X_valid_kf, y_valid_kf, cat_features=cat_col)\n\n#         # 学習\n#         model_cb = CatBoostClassifier(**cat_params)\n#         model_cb.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50)\n\n#         preds = model_cb.predict_proba(X_valid_kf)[:,1]\n#         score = roc_auc_score(y_valid_kf, preds)\n#         scores.append(score)\n\n#     return np.mean(scores)\n\n# # --- Optuna 実行 ---\n# study = optuna.create_study(direction=\"maximize\",\n#                             pruner=optuna.pruners.MedianPruner())\n# study.optimize(objective, n_trials=5)\n\n# print(\"Best Score:\", study.best_value)\n# print(\"Best Params:\", study.best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:40:49.575587Z","iopub.execute_input":"2025-08-27T12:40:49.575909Z","iopub.status.idle":"2025-08-27T13:20:33.838733Z","shell.execute_reply.started":"2025-08-27T12:40:49.575885Z","shell.execute_reply":"2025-08-27T13:20:33.837895Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【CatBoost】","metadata":{}},{"cell_type":"code","source":"#################################################\n############ CatBoost (Classifier版) ############\n#################################################\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\n# 学習、バリデーションデータ\npred_cb = np.zeros(len(train_df))\npred_cb_test = np.zeros(len(test_df))\nmodels_cb = []\ncb_auc_valid = []  # foldごとのAUC履歴\n\n# 入力データ\nX = X_train_enc\ny = y_train\nX_test = X_test_enc\n\n# CatBoostパラメータ\ncat_params = {\n    \"loss_function\": \"Logloss\",\n    \"eval_metric\": \"AUC\",\n    \"depth\": 8,                   # 6〜10\n    \"learning_rate\": 0.05,        # 0.03〜0.1\n    \"iterations\": 2000,          # 大きめ＋ES\n    \"bootstrap_type\": \"Bayesian\", # 精度安定\n    \"boosting_type\": \"Ordered\",   # 多カテゴリに強い\n    \"random_strength\": 1.0,       # 0.5〜2.0で微調整\n    \"task_type\": \"GPU\",\n    # \"task_type\": \"CPU\",           # このデータ規模ならCPUの方が速い/安定なこと多い\n    \"verbose\": 100,\n}\n\n# Stratified KFold\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n\n    print(\"#\" * 25)\n    print(f\"### Fold {fold+1}\")\n    print(\"#\" * 25)\n\n    # データ分割\n    X_train_kf = X.iloc[train_idx, :]\n    y_train_kf = y.iloc[train_idx]\n    X_valid_kf = X.iloc[valid_idx, :]\n    y_valid_kf = y.iloc[valid_idx]\n\n    # object型をカテゴリ型に変換\n    for col in cat_col:\n        X_train_kf.loc[:, col] = X_train_kf.loc[:, col].astype(\"category\")\n        X_valid_kf.loc[:, col] = X_valid_kf.loc[:, col].astype(\"category\")\n\n    # Poolを作成\n    train_pool = Pool(X_train_kf, y_train_kf, cat_features=cat_col)\n    valid_pool = Pool(X_valid_kf, y_valid_kf, cat_features=cat_col)\n\n    # モデル作成 & 学習\n    model_cb = CatBoostClassifier(**cat_params)\n    model_cb.fit(\n        train_pool,\n        eval_set=valid_pool,\n        early_stopping_rounds=100,\n        use_best_model=True\n    )\n\n    # バリデーション予測\n    pred_cb[valid_idx] = model_cb.predict_proba(X_valid_kf)[:, 1]\n\n    # モデル保存\n    models_cb.append(model_cb)\n\n    # foldごとのベストスコアを保存\n    cb_auc_valid.append(model_cb.get_best_score()[\"validation\"][\"AUC\"])\n\n    # テスト予測\n    pred_cb_test += model_cb.predict_proba(X_test)[:, 1]\n\n# FOLD数で割って平均化\npred_cb_test = pred_cb_test / skf.n_splits\n\nprint(\"各foldのAUC:\", cb_auc_valid)\nprint(\"平均AUC:\", np.mean(cb_auc_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:42:06.887389Z","iopub.execute_input":"2025-08-29T14:42:06.888002Z","iopub.status.idle":"2025-08-29T14:42:51.459643Z","shell.execute_reply.started":"2025-08-29T14:42:06.887977Z","shell.execute_reply":"2025-08-29T14:42:51.458779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# スコア表示\nAUC_cb = roc_auc_score(y,pred_cb)\nF1_cb = f1_score(y,np.round(pred_cb,0))\nprint(f\"CB: AUC score = {AUC_cb}, F1 = {F1_cb}\")\n\n# # 学習履歴を一番短いfoldに揃える\n# min_len = min(len(m) for m in cb_auc_valid)\n# cb_auc_score = [m[:min_len] for m in cb_auc_valid]\n\n# # foldごとの結果を平均する\n# cb_auc_score = np.average(cb_auc_score,axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:43:52.848416Z","iopub.execute_input":"2025-08-29T14:43:52.848713Z","iopub.status.idle":"2025-08-29T14:43:53.737828Z","shell.execute_reply.started":"2025-08-29T14:43:52.848691Z","shell.execute_reply":"2025-08-29T14:43:53.737199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = pred_cb_test\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import  matplotlib.pyplot as plt\n# # 履歴の可視化\n# plt.plot(cb_auc_score, label='Validation')\n# plt.xlabel('Iteration')\n# plt.ylabel('AUC')\n# plt.grid()\n# plt.legend()\n# plt.title(\"CabBoost AUC\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Stacking","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nprint(\"# STACKING ENSEMBLE IMPLEMENTATION\")\nprint(\"# \" + \"=\"*50)\nprint(\"# Combining top 3 models: LightGBM, XGBoost, CatBoost\")\nprint(\"# Meta-learner: Logistic Regression\")\nprint(\"# \" + \"=\"*50)\n\nstacking_train = pd.DataFrame({\n    'lgb': pred_lgb,\n    'xgb': pred_xgb, \n    'cat': pred_cb\n})\n\nstacking_test = pd.DataFrame({\n    'lgb': pred_lgb_test,\n    'xgb': pred_xgb_test,\n    'cat': pred_cb_test\n})\n\nprint(f\"# Stacking train shape: {stacking_train.shape}\")\nprint(f\"# Stacking test shape: {stacking_test.shape}\")\n\nprint(\"\\n# METHOD 1: WEIGHTED AVERAGE\")\nprint(\"# \" + \"-\"*30)\n\nscores = [AUC_lgb, AUC_xgb, AUC_cb]  \ntotal_score = sum(scores)\nweights = [score/total_score for score in scores]\n\nprint(f\"# Model weights:\")\nprint(f\"# LightGBM: {weights[0]:.4f}\")\nprint(f\"# XGBoost:  {weights[1]:.4f}\")\nprint(f\"# CatBoost: {weights[2]:.4f}\")\n\nweighted_oof = (stacking_train['lgb'] * weights[0] + \n                stacking_train['xgb'] * weights[1] + \n                stacking_train['cat'] * weights[2])\n\nweighted_test = (stacking_test['lgb'] * weights[0] + \n                 stacking_test['xgb'] * weights[1] + \n                 stacking_test['cat'] * weights[2])\n\nweighted_score = roc_auc_score(y, weighted_oof)\nprint(f\"# Weighted Average ROC AUC: {weighted_score:.6f}\")\n\nprint(\"\\n# METHOD 2: LOGISTIC REGRESSION META-LEARNER\")\nprint(\"# \" + \"-\"*40)\n\nmeta_learner = LogisticRegression(random_state=42, max_iter=1000)\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ncv_scores = cross_val_score(meta_learner, stacking_train, y, \n                           cv=skf, scoring='roc_auc', n_jobs=-1)\n\nprint(f\"# Meta-learner CV scores: {[f'{score:.6f}' for score in cv_scores]}\")\nprint(f\"# Meta-learner mean CV: {cv_scores.mean():.6f} ± {cv_scores.std():.6f}\")\n\nmeta_learner.fit(stacking_train, y)\nmeta_oof = meta_learner.predict_proba(stacking_train)[:, 1]\nmeta_test = meta_learner.predict_proba(stacking_test)[:, 1]\nmeta_score = roc_auc_score(y, meta_oof)\n\nprint(f\"# Meta-learner ROC AUC: {meta_score:.6f}\")\n\ncoefficients = meta_learner.coef_[0]\nprint(f\"# Meta-learner coefficients:\")\nprint(f\"# LightGBM: {coefficients[0]:.4f}\")\nprint(f\"# XGBoost:  {coefficients[1]:.4f}\")\nprint(f\"# CatBoost: {coefficients[2]:.4f}\")\nprint(f\"# Intercept: {meta_learner.intercept_[0]:.4f}\")\n\nprint(\"\\n# METHOD 3: SIMPLE AVERAGE (BASELINE)\")\nprint(\"# \" + \"-\"*35)\n\nsimple_oof = (stacking_train['lgb'] + stacking_train['xgb'] + stacking_train['cat']) / 3\nsimple_test = (stacking_test['lgb'] + stacking_test['xgb'] + stacking_test['cat']) / 3\nsimple_score = roc_auc_score(y, simple_oof)\n\nprint(f\"# Simple Average ROC AUC: {simple_score:.6f}\")\n\nprint(\"\\n# ENSEMBLE METHODS COMPARISON\")\nprint(\"# \" + \"=\"*40)\nensemble_results = [\n    ('Individual LightGBM', AUC_lgb),\n    ('Individual XGBoost', AUC_xgb),\n    ('Individual CatBoost', AUC_cb),\n    ('Weighted Average', weighted_score),\n    ('Meta-learner (LogReg)', meta_score),\n    ('Simple Average', simple_score)\n]\n\nensemble_results.sort(key=lambda x: x[1], reverse=True)\n\nfor i, (method, score) in enumerate(ensemble_results, 1):\n    print(f\"# {i}. {method:<25}: {score:.6f}\")\n\nbest_method, best_score = ensemble_results[0]\nprint(f\"\\n# BEST ENSEMBLE METHOD: {best_method}\")\nprint(f\"# BEST ENSEMBLE SCORE: {best_score:.6f}\")\n\nif 'Meta-learner' in best_method:\n    final_oof = meta_oof\n    final_test = meta_test\n    print(\"# Using Meta-learner predictions for final submission\")\nelif 'Weighted' in best_method:\n    final_oof = weighted_oof\n    final_test = weighted_test\n    print(\"# Using Weighted Average predictions for final submission\")\nelse:\n    final_oof = simple_oof\n    final_test = simple_test\n    print(\"# Using Simple Average predictions for final submission\")\n\nprint(\"\\n# STACKING ENSEMBLE COMPLETED!\")\nprint(\"# \" + \"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:44:38.43662Z","iopub.execute_input":"2025-08-29T14:44:38.43689Z","iopub.status.idle":"2025-08-29T14:44:44.981259Z","shell.execute_reply.started":"2025-08-29T14:44:38.436871Z","shell.execute_reply":"2025-08-29T14:44:44.980461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 提出データ作成\nsample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\nsample_submission['y'] = final_test\nsample_submission.to_csv('submission.csv', index=False)\nprint('Submission file saved.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:44:51.128505Z","iopub.execute_input":"2025-08-29T14:44:51.128789Z","iopub.status.idle":"2025-08-29T14:44:51.672967Z","shell.execute_reply.started":"2025-08-29T14:44:51.12877Z","shell.execute_reply":"2025-08-29T14:44:51.672299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 【Neural Net】","metadata":{}},{"cell_type":"code","source":"# import random\n# import os\n# import pandas as pd\n# import numpy as np\n# from tqdm.notebook import tqdm\n# import matplotlib.pyplot as plt\n\n# import torch\n# import torch.nn as nn\n# from torch.utils.data import Dataset, DataLoader\n\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.preprocessing import LabelEncoder\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\n# from sklearn.metrics import f1_score\n\n# # pytorch実装\n# import torch # Tensorの作成や操作\n# import torch.nn as nn # ニューラルネットワーク\n# import torch.nn.functional as F # 関数をメソッドとして提供\n# import torch.optim as optim # オプティマイザ\n# from torch.utils.data import Dataset, DataLoader\n# from torch.autograd import Variable\n\n# from sklearn.model_selection import StratifiedKFold\n# from sklearn.metrics import roc_auc_score\n# from tqdm.notebook import tqdm\n# # from tqdm import tqdm\n# import matplotlib.pyplot as plt\n# import time\n\n# # GPUの使用状況確認\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# print(device)\n\n# all_df = all_df_NN\n# all_df = all_df.drop([\"id\",\"y\"],axis=1)\n# y = train_df[\"y\"]\n\n# # 設定\n# SEED = 42\n# TARGET = \"y\"\n\n# CATEGORICAL = cat_col\n# NUMERICAL = num_col\n# USE = CATEGORICAL + NUMERICAL\n# # df_train = train_df.drop(\"id\",axis=1)\n# # df_test = test_df.drop(\"id\",axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:16:42.170832Z","iopub.execute_input":"2025-08-24T10:16:42.171702Z","iopub.status.idle":"2025-08-24T10:16:46.845965Z","shell.execute_reply.started":"2025-08-24T10:16:42.17167Z","shell.execute_reply":"2025-08-24T10:16:46.845091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (1) 住宅ローン + ローン\n# all_df[\"housing_loan\"] = all_df[\"housing\"].astype(str) + \"_\" + all_df[\"loan\"].astype(str)\n\n# # (2) コンタクト時間 x 年齢\n# all_df[\"duration_x_age\"] = all_df[\"duration\"] * all_df[\"age\"]\n\n# # (3) sin,cos(コンタクト時間)\n# all_df['duration_sin'] = np.sin(2*np.pi * all_df['duration'] / 400)\n# all_df['duration_cos'] = np.cos(2*np.pi * all_df['duration'] / 400)\n\n# # (4) monthを数値に直し周期的に使う\n# month_map = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4,\n#     'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n#     'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n# all_df['month_num'] = all_df['month'].map(month_map).astype('int')\n# all_df['month_sin'] = np.sin(2 * np.pi * all_df['month_num'] / 12)\n# all_df['month_cos'] = np.cos(2 * np.pi * all_df['month_num'] / 12)\n\n# # (5) コンタクト時間をカテゴリ化\n# all_df['duration_bin'] = pd.cut(\n#     all_df['duration'],\n#     bins=[0, 60, 300, 600, 900, float('inf')],\n#     labels=['short', 'medium', 'long', 'very_long', 'extreme'],\n#     right=False)\n# all_df['duration_bin'] = all_df['duration_bin'].astype(\"object\")\n\n# # (6) 連絡手段 + 年齢\n# all_df['age_group'] = pd.cut(\n#     all_df['age'],\n#     bins=[0, 30, 45, 60, 100],\n#     labels=['young', 'mid', 'senior', 'elder'])\n# all_df[\"contact_age\"] = all_df[\"contact\"].astype(str) + \"_\" + all_df[\"age_group\"].astype(str)\n# all_df = all_df.drop(\"age_group\",axis=1)\n\n# # (7) sin,cos(pdays)\n# all_df['pdays_sin'] = np.sin(2*np.pi * all_df['pdays'] / 90)\n# all_df['pdays_cos'] = np.cos(2*np.pi * all_df['pdays'] / 90)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:16:46.847307Z","iopub.execute_input":"2025-08-24T10:16:46.847789Z","iopub.status.idle":"2025-08-24T10:16:47.914084Z","shell.execute_reply.started":"2025-08-24T10:16:46.847767Z","shell.execute_reply":"2025-08-24T10:16:47.913287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 標準化 + ラベルエンコード\n# def preprocessing(all_df, cat_cols=CATEGORICAL, num_cols=NUMERICAL, target=TARGET):\n\n#     # 訓練データとテストデータに分離\n#     train = all_df[:len(train_df)]\n#     test = all_df[len(train_df):]\n\n#     # y = train[target]\n#     # train = train.drop(\"y\",axis=1)\n#     train_len = len(train)\n\n#     # 訓練データ + テストデータ\n#     # df = pd.concat([train.drop(columns=target), test])\n#     # y = train[target]\n#     # train_len = len(train)\n    \n#     # 欠損埋め\n#     # df[cat_cols] = df[cat_cols].fillna('None')\n#     # df[num_cols] = df[num_cols].fillna(0)\n\n#     # train = df[:train_len]\n#     # test = df[train_len:]\n\n#     # 標準化\n#     scaler = StandardScaler()\n\n#     # フィッティング\n#     # scaler.fit(df[num_cols])\n#     scaler.fit(train[num_cols])\n\n#     # 適用\n#     train[num_cols] = scaler.transform(train[num_cols])\n#     test[num_cols] = scaler.transform(test[num_cols])\n#     df = pd.concat([train, test])\n    \n#     # ラベルエンコーダ\n#     for col in df.columns:\n#         if col in cat_cols:\n#             df[col] = LabelEncoder().fit_transform(df[col])\n#             df[col]= df[col].astype('category')\n            \n#     return pd.concat([df.iloc[:train_len], y], axis=1), df.iloc[train_len:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:16:47.914841Z","iopub.execute_input":"2025-08-24T10:16:47.915068Z","iopub.status.idle":"2025-08-24T10:16:47.921586Z","shell.execute_reply.started":"2025-08-24T10:16:47.915048Z","shell.execute_reply":"2025-08-24T10:16:47.920837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 前処理の実施\n# df_train, df_test = preprocessing(all_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:16:47.922923Z","iopub.execute_input":"2025-08-24T10:16:47.923158Z","iopub.status.idle":"2025-08-24T10:16:50.893563Z","shell.execute_reply.started":"2025-08-24T10:16:47.923135Z","shell.execute_reply":"2025-08-24T10:16:50.892719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # データセット関数\n# class CustomDataset(Dataset):\n\n#     # オブジェクト定義\n#     def __init__(self, df, target, cat_cols=CATEGORICAL):\n#         self.df_cat = df[cat_cols]\n#         self.df_num = df.drop(cat_cols, axis=1)\n#         self.X_cats = self.df_cat.values.astype(np.int64)\n#         self.X_nums = self.df_num.values.astype(np.float32)\n#         self.target = target.values.astype(np.int64)\n\n#     # データセットのサイズを返す\n#     def __len__(self):\n#         return len(self.target)\n\n#     # 指定したインデックスのデータとラベルを返す\n#     def __getitem__(self, idx):\n#         return [self.X_cats[idx], self.X_nums[idx], self.target[idx]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:16:50.894408Z","iopub.execute_input":"2025-08-24T10:16:50.894711Z","iopub.status.idle":"2025-08-24T10:16:50.900249Z","shell.execute_reply.started":"2025-08-24T10:16:50.894684Z","shell.execute_reply":"2025-08-24T10:16:50.899468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # NNモデル作成\n# class NN_Model(nn.Module):\n\n#     # ネットワーク構造の定義\n#     def __init__(self, embedding_sizes, n_num):\n#         super().__init__()\n#         self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories, size in embedding_sizes])\n#         n_emb = sum(e.embedding_dim for e in self.embeddings)\n#         self.n_emb, self.n_num = n_emb, n_num\n#         self.lin1 = nn.Linear(self.n_emb + self.n_num, 100)\n#         self.lin2 = nn.Linear(100, 70)\n#         self.lin3 = nn.Linear(70, 2)\n#         self.bn1 = nn.BatchNorm1d(self.n_num)\n#         self.bn2 = nn.BatchNorm1d(100)\n#         self.bn3 = nn.BatchNorm1d(70)\n#         self.emb_drop = nn.Dropout(0.6)\n#         self.drops = nn.Dropout(0.3)\n \n#     # 順伝播\n#     def forward(self,x_cat,x_num):\n#         x = [e(x_cat[:, i]) for i, e in enumerate(self.embeddings)]\n#         x = torch.cat(x, dim=1)\n#         x = self.emb_drop(x)\n#         x2 = self.bn1(x_num)\n#         x = torch.cat([x, x2], dim=1)\n#         x = F.relu(self.lin1(x))\n#         x = self.drops(x)\n#         x = self.bn2(x)\n#         x = F.relu(self.lin2(x))\n#         x = self.drops(x)\n#         x = self.bn3(x)\n#         x = self.lin3(x)\n#         return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:16:50.901878Z","iopub.execute_input":"2025-08-24T10:16:50.902137Z","iopub.status.idle":"2025-08-24T10:16:50.934768Z","shell.execute_reply.started":"2025-08-24T10:16:50.90212Z","shell.execute_reply":"2025-08-24T10:16:50.933919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ラベルエンコード済みカテゴリ変数の埋め込み\n# # 各カテゴリ列の変数の種類\n# cat_sizes = [len(df_train[col].cat.categories) for col in CATEGORICAL]\n\n# # (入力サイズ, 50と割る2の小さい方)でエンコード\n# emb_sizes = [(size, min(50, (size+1)//2)) for size in cat_sizes]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:16:52.259867Z","iopub.execute_input":"2025-08-24T10:16:52.260418Z","iopub.status.idle":"2025-08-24T10:16:52.265319Z","shell.execute_reply.started":"2025-08-24T10:16:52.26039Z","shell.execute_reply":"2025-08-24T10:16:52.264509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 記録用\n# hist = {\n#     'train_loss': [], 'train_auc': [],\n#     'val_loss': [], 'val_auc': []\n# }\n\n# # パラメータ\n# bs = 64 # バッチサイズ\n# EPOCHS = 5 # エポック\n# save_every = 1\n# FOLDS = 5 # FOLD数\n# LR=1e-3 # 学習率\n\n# patience = 3\n\n# # stratified KFoldの宣言\n# skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\n# fold_results = []\n\n# val_results = []\n# test_results = []\n\n# # SKFによるデータ分割\n# for fold, (train_idx, val_idx) in enumerate(skf.split(df_train.drop(columns=TARGET), df_train[TARGET])):\n    \n#     print(f\"\\n========== Fold {fold+1} ==========\")\n\n#     # 学習データ\n#     X_train = df_train.drop(columns=TARGET).iloc[train_idx] \n#     y_train = df_train[TARGET].iloc[train_idx]\n\n#     # バリデーションデータ\n#     X_val = df_train.drop(columns=TARGET).iloc[val_idx]\n#     y_val = df_train[TARGET].iloc[val_idx]\n\n#     # Datasetの作成\n#     train_dataset = CustomDataset(X_train, y_train)\n#     val_dataset = CustomDataset(X_val, y_val)\n    \n#     # DataLoaderの作成\n#     train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=0)\n#     val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=0)\n\n#     # モデル構築\n#     model = NN_Model(emb_sizes, len(NUMERICAL)).to(device)\n\n#     # 最適化設定\n#     optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n#     # optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n#     # 損失関数\n#     criterion = nn.CrossEntropyLoss()\n\n#     hist = {\"train_auc\": [], \"val_auc\": []}\n#     best_val_auc = 0\n#     counter = 0\n\n#     # 学習・予測エポックのループ\n#     for epoch in range(EPOCHS):\n\n#         # 開始時間\n#         start_time = time.time()\n\n#         # 学習モード\n#         model.train()\n\n#         # ラベル、予測値の保存場所\n#         y_true_train, y_pred_train = [], []\n\n#         # プログレスバー\n#         train_iter = tqdm(train_loader, desc=f\"<Train> Epoch {epoch+1}\", leave=False)\n        \n#         for i, (cat_data, num_data, target) in enumerate(train_iter):\n\n#             # DataLoaderから取り出した、カテゴリ、数値、ターゲット\n#             cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n\n#             # パラメータの勾配を初期化\n#             optimizer.zero_grad()\n\n#             # 予測値の算出\n#             output = model(cat_data, num_data)\n\n#             # ラベルと予測値とのロス計算\n#             loss = criterion(output, target)\n\n#             # 各パラメータの勾配を算出\n#             loss.backward()\n\n#             # パラメータ更新\n#             optimizer.step()\n\n#             # ソフトマックスの分類結果を格納\n#             probs = torch.softmax(output, dim=1)[:, 1].detach().cpu().numpy()\n#             y_pred_train.extend(probs)\n\n#             # ラベルの格納\n#             y_true_train.extend(target.cpu().numpy())\n\n#             # プログレスバーの後ろにロス値を表示\n#             if i % 10 == 0:\n#                 train_iter.set_postfix(loss=loss.item())\n\n#         # チェックポイント保存\n#         if (epoch + 1) % save_every == 0:\n#             torch.save(model.state_dict(), f\"model_epoch{epoch+1}.pt\")        \n    \n#         # histに残すAUCスコア\n#         train_auc = roc_auc_score(y_true_train, y_pred_train)\n\n#         # 評価モード\n#         model.eval()\n\n#         # ラベル、予測値の保存場所        \n#         y_true_val, y_pred_val = [], []\n\n#         # プログレスバー\n#         val_iter = tqdm(val_loader, desc=f\"<Val> Epoch {epoch+1}\", leave=False)\n\n#         # 勾配を更新しない\n#         with torch.no_grad():\n            \n#             for cat_data, num_data, target in val_iter:\n    \n#                 # DataLoaderから取り出した、カテゴリ、数値、ターゲット\n#                 cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n\n#                 # 予測値の算出\n#                 output = model(cat_data, num_data)\n\n#                 # ソフトマックスの分類結果を格納\n#                 probs = torch.softmax(output, dim=1)[:, 1].cpu().numpy()\n#                 y_pred_val.extend(probs)\n\n#                 # ラベルの格納\n#                 y_true_val.extend(target.cpu().numpy())\n\n#                 # プログレスバーの後ろにロス値を表示\n#                 val_iter.set_postfix(loss=criterion(output, target).item())\n\n#         # histに残すAUCスコア        \n#         val_auc = roc_auc_score(y_true_val, y_pred_val)\n\n#         # 差分時刻\n#         elapsed = time.time() - start_time\n\n#         # 履歴追加\n#         hist[\"train_auc\"].append(train_auc)\n#         hist[\"val_auc\"].append(val_auc)\n\n#         # 進捗\n#         print(f\"Epoch {epoch+1}/{EPOCHS} - TrainAUC: {train_auc:.4f} | ValAUC: {val_auc:.4f} | Time: {elapsed:.1f}s\")\n\n#         # チェックポイント\n#         if (epoch + 1) % save_every == 0:\n#             torch.save(model.state_dict(), f\"model_fold{fold+1}_epoch{epoch+1}.pth\")\n\n#         # EarlyStopping判定\n#         if val_auc > best_val_auc:\n#             best_val_auc = val_auc\n#             counter = 0\n#             torch.save(model.state_dict(), f\"best_model_fold{fold+1}.pth\")\n#         else:\n#             counter += 1\n#             if counter >= patience:\n#                 print(f\"Early stopping at epoch {epoch+1}\")\n#                 break\n\n    \n#     # foldごとに保存\n#     torch.save(model.state_dict(), f\"model_fold{fold+1}.pth\")\n    \n#     # ヒストグラムの更新\n#     fold_results.append(hist)\n\n#     # foldごとにテストデータ計算\n#     model.eval()\n#     with torch.no_grad():\n#         X_val_cat = torch.from_numpy(df_train[CATEGORICAL].values.astype(np.int64)).to(device)\n#         X_val_num = torch.from_numpy(df_train[NUMERICAL].values.astype(np.float32)).to(device)\n\n#         # 予測\n#         preds = torch.softmax(model(X_val_cat, X_val_num),dim=1)[:,1].cpu().numpy()\n#         val_results.append(preds)\n        \n#         X_test_cat = torch.from_numpy(df_test[CATEGORICAL].values.astype(np.int64)).to(device)\n#         X_test_num = torch.from_numpy(df_test[NUMERICAL].values.astype(np.float32)).to(device)\n\n#         # 予測\n#         preds = torch.softmax(model(X_test_cat, X_test_num),dim=1)[:,1].cpu().numpy()\n#         # preds = torch.softmax(model(X_test_cat, X_test_num).squeeze()).cpu().numpy()\n#         test_results.append(preds)\n    \n# # shape = (n_folds, n_test_samples) → 平均化\n# val_results = np.mean(val_results, axis=0)        \n# test_results = np.mean(test_results, axis=0)        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T13:05:32.122769Z","iopub.execute_input":"2025-08-24T13:05:32.123584Z","iopub.status.idle":"2025-08-24T13:09:58.601929Z","shell.execute_reply.started":"2025-08-24T13:05:32.123555Z","shell.execute_reply":"2025-08-24T13:09:58.601052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pred_NN = val_results\n# pred_NN_test = test_results\n# AUC_NN = np.average(hist[\"val_auc\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ======================\n# # FoldごとのAUCをプロット\n# # ======================\n# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10,5))\n# for i, hist in enumerate(fold_results):\n#     plt.plot(hist[\"val_auc\"], label=f\"Fold {i+1} Val AUC\")\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"AUC\")\n# plt.legend()\n# plt.title(\"Validation AUC per Fold\")\n# plt.show() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T13:16:03.58252Z","iopub.execute_input":"2025-08-24T13:16:03.58329Z","iopub.status.idle":"2025-08-24T13:16:03.825238Z","shell.execute_reply.started":"2025-08-24T13:16:03.583263Z","shell.execute_reply":"2025-08-24T13:16:03.824485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.ensemble import StackingClassifier\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import cross_val_score, StratifiedKFold\n# from sklearn.metrics import roc_auc_score\n\n# print(\"# STACKING ENSEMBLE IMPLEMENTATION\")\n# print(\"# \" + \"=\"*50)\n# print(\"# Combining top 4 models: LightGBM, XGBoost, CatBoost, NN\")\n# print(\"# Meta-learner: Logistic Regression\")\n# print(\"# \" + \"=\"*50)\n\n# stacking_train = pd.DataFrame({\n#     'lgb': pred_lgb,\n#     'xgb': pred_xgb, \n#     'cat': pred_cb,\n#     'NN': pred_NN,\n# })\n\n# stacking_test = pd.DataFrame({\n#     'lgb': pred_lgb_test,\n#     'xgb': pred_xgb_test,\n#     'cat': pred_cb_test,\n#     'NN': pred_NN_test,\n# })\n\n# print(f\"# Stacking train shape: {stacking_train.shape}\")\n# print(f\"# Stacking test shape: {stacking_test.shape}\")\n\n# print(\"\\n# METHOD 1: WEIGHTED AVERAGE\")\n# print(\"# \" + \"-\"*30)\n\n# scores = [AUC_lgb, AUC_xgb, AUC_cb, AUC_NN]  \n# total_score = sum(scores)\n# weights = [score/total_score for score in scores]\n\n# print(f\"# Model weights:\")\n# print(f\"# LightGBM: {weights[0]:.4f}\")\n# print(f\"# XGBoost:  {weights[1]:.4f}\")\n# print(f\"# CatBoost: {weights[2]:.4f}\")\n# print(f\"# NN: {weights[3]:.4f}\")\n\n# weighted_oof = (stacking_train['lgb'] * weights[0] + \n#                 stacking_train['xgb'] * weights[1] + \n#                 stacking_train['cat'] * weights[2] +\n#                 stacking_train['NN'] * weights[3])\n\n# weighted_test = (stacking_test['lgb'] * weights[0] + \n#                  stacking_test['xgb'] * weights[1] + \n#                  stacking_test['cat'] * weights[2] +\n#                  stacking_test['NN'] * weights[3])\n\n# weighted_score = roc_auc_score(y, weighted_oof)\n# print(f\"# Weighted Average ROC AUC: {weighted_score:.6f}\")\n\n# print(\"\\n# METHOD 2: LOGISTIC REGRESSION META-LEARNER\")\n# print(\"# \" + \"-\"*40)\n\n# meta_learner = LogisticRegression(penalty=\"l2\",random_state=42, max_iter=1000)\n# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# cv_scores = cross_val_score(meta_learner, stacking_train, y, \n#                            cv=skf, scoring='roc_auc', n_jobs=-1)\n\n# print(f\"# Meta-learner CV scores: {[f'{score:.6f}' for score in cv_scores]}\")\n# print(f\"# Meta-learner mean CV: {cv_scores.mean():.6f} ± {cv_scores.std():.6f}\")\n\n# meta_learner.fit(stacking_train, y)\n# meta_oof = meta_learner.predict_proba(stacking_train)[:, 1]\n# meta_test = meta_learner.predict_proba(stacking_test)[:, 1]\n# meta_score = roc_auc_score(y, meta_oof)\n\n# print(f\"# Meta-learner ROC AUC: {meta_score:.6f}\")\n\n# coefficients = meta_learner.coef_[0]\n# print(f\"# Meta-learner coefficients:\")\n# print(f\"# LightGBM: {coefficients[0]:.4f}\")\n# print(f\"# XGBoost:  {coefficients[1]:.4f}\")\n# print(f\"# CatBoost: {coefficients[2]:.4f}\")\n# print(f\"# NN: {coefficients[3]:.4f}\")\n# print(f\"# Intercept: {meta_learner.intercept_[0]:.4f}\")\n\n# print(\"\\n# METHOD 3: SIMPLE AVERAGE (BASELINE)\")\n# print(\"# \" + \"-\"*35)\n\n# simple_oof = (stacking_train['lgb'] + stacking_train['xgb'] + stacking_train['cat'] + stacking_train['NN']) / 4\n# simple_test = (stacking_test['lgb'] + stacking_test['xgb'] + stacking_test['cat'] + stacking_test['NN']) / 4\n# simple_score = roc_auc_score(y, simple_oof)\n\n# print(f\"# Simple Average ROC AUC: {simple_score:.6f}\")\n\n# print(\"\\n# ENSEMBLE METHODS COMPARISON\")\n# print(\"# \" + \"=\"*40)\n# ensemble_results = [\n#     ('Individual LightGBM', AUC_lgb),\n#     ('Individual XGBoost', AUC_xgb),\n#     ('Individual CatBoost', AUC_cb),\n#     ('Individual NN', AUC_NN),\n#     ('Weighted Average', weighted_score),\n#     ('Meta-learner (LogReg)', meta_score),\n#     ('Simple Average', simple_score)\n# ]\n\n# ensemble_results.sort(key=lambda x: x[1], reverse=True)\n\n# for i, (method, score) in enumerate(ensemble_results, 1):\n#     print(f\"# {i}. {method:<25}: {score:.6f}\")\n\n# best_method, best_score = ensemble_results[0]\n# print(f\"\\n# BEST ENSEMBLE METHOD: {best_method}\")\n# print(f\"# BEST ENSEMBLE SCORE: {best_score:.6f}\")\n\n# if 'Meta-learner' in best_method:\n#     final_oof = meta_oof\n#     final_test = meta_test\n#     print(\"# Using Meta-learner predictions for final submission\")\n# elif 'Weighted' in best_method:\n#     final_oof = weighted_oof\n#     final_test = weighted_test\n#     print(\"# Using Weighted Average predictions for final submission\")\n# else:\n#     final_oof = simple_oof\n#     final_test = simple_test\n#     print(\"# Using Simple Average predictions for final submission\")\n\n# print(\"\\n# STACKING ENSEMBLE COMPLETED!\")\n# print(\"# \" + \"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T13:16:11.553346Z","iopub.execute_input":"2025-08-24T13:16:11.553673Z","iopub.status.idle":"2025-08-24T13:16:17.533785Z","shell.execute_reply.started":"2025-08-24T13:16:11.553648Z","shell.execute_reply":"2025-08-24T13:16:17.533081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 提出データ作成\n# sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\n# sample_submission['y'] = test_results\n# sample_submission.to_csv('submission.csv', index=False)\n# print('Submission file saved.')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}