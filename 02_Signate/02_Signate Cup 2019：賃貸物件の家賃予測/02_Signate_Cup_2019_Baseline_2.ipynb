{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpVgqffgJkZ-"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rINd5svKOEQ",
        "outputId": "159892e3-194f-4211-fdb3-fda45d326715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: lightgbm 4.5.0\n",
            "Uninstalling lightgbm-4.5.0:\n",
            "  Successfully uninstalled lightgbm-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall lightgbm --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZcShXrsKcYI",
        "outputId": "bab5baf8-d0c7-4052-8aca-5be3117ff122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m151.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.14.1)\n",
            "Building wheels for collected packages: lightgbm\n",
            "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightgbm: filename=lightgbm-4.6.0-py3-none-linux_x86_64.whl size=61749734 sha256=fe89a34a9839aee977d3b4f4503855427e6b559982c84f91770309fd72ce72c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jc8jmiat/wheels/ee/da/90/bd694ce19848ae41071e6c926d1650e4581556bf5869a57fe0\n",
            "Successfully built lightgbm\n",
            "Installing collected packages: lightgbm\n",
            "Successfully installed lightgbm-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm \\\n",
        "    --no-binary lightgbm \\\n",
        "    --no-cache lightgbm \\\n",
        "    --config-settings=cmake.define.USE_CUDA=ON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hivObPV8feEu",
        "outputId": "92b09707-62a2-4191-8b16-32b0607a8ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzosrRw_gtPD",
        "outputId": "02aaffb4-312f-457e-8f1c-e2abda0b3816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download 100%.\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'signate.json'\", fields=\"files(id)\").execute()\n",
        "signate_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/root/.signate/signate.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=signate_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVbfUC1zwaQX",
        "outputId": "4476dd75-039a-4c49-e677-aabf7e5f56af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting signate\n",
            "  Downloading signate-0.9.10-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from signate) (8.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from signate) (0.9.0)\n",
            "Collecting wget (from signate)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.26.7 in /usr/local/lib/python3.11/dist-packages (from signate) (2.3.0)\n",
            "Requirement already satisfied: six>=1.16 in /usr/local/lib/python3.11/dist-packages (from signate) (1.17.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from signate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from signate) (2.8.2)\n",
            "Downloading signate-0.9.10-py3-none-any.whl (37 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=a5881c123c6495411a64cf68a2d05cda398f20bc58b1d432609134fd2e81e4c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, signate\n",
            "Successfully installed signate-0.9.10 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install signate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n5cHpxpzfk6v",
        "outputId": "22f3dc71-cbbb-49c1-9801-c7608309e66c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submit.csv\n",
            "\n",
            "test.csv\n",
            "\n",
            "train.csv\n",
            "\n",
            "\u001b[32m\n",
            "Download completed.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !signate list\n",
        "# ! signate files --competition-id=264\n",
        "!signate download --competition-id=264"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02kyeQxtht-Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ヘッダ有りとヘッダ無しCSVに区別して読み取る\n",
        "train = pd.read_csv(\"/content/train.csv\", header=0)\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "submit = pd.read_csv(\"/content/sample_submit.csv\", header=None, names=[\"id\", \"賃料\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"賃料\"] = train[\"賃料\"].apply(np.log)"
      ],
      "metadata": {
        "id": "w6Deu782hfig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id1puSulF-J6"
      },
      "outputs": [],
      "source": [
        "# データ結合(番号を振り直す)\n",
        "combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
        "max_row = combined.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 賃料を対数グラフにする\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "# ax.hist(train[\"賃料\"].apply(np.log),bins=100)\n",
        "# fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "CTREPzXNgTir",
        "outputId": "910dbfe0-dc83-42bd-931f-4877d0e020d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2EJgw4AqX0k"
      },
      "outputs": [],
      "source": [
        "# 編集する特徴量\n",
        "# (OK)所在地 = 区しか利用価値ないためOK\n",
        "# (OK)アクセス = 路線、最寄り駅、徒歩○分\n",
        "# (そのままで)間取り = そのまま\n",
        "# (OK)築年数 = ヶ月単位に変換\n",
        "# (そのままで)方角 = そのまま、南向き、西向きのフラグが良いかも\n",
        "# (OK)面積 = 数値に治す\n",
        "# (済)所在階 = 階数に変換\n",
        "#----------------------------------------休憩\n",
        "# (OK)バス・トイレ = バス・トイレ別フラグ\n",
        "# (OK)キッチン = コンロタイプで分類\n",
        "# (OK)放送・通信 = ネット対応、ケーブルテレビ、CS\n",
        "#----------------------------------------休憩\n",
        "# (OK)室内設備 = エアコン、シューズボックス\n",
        "# (OK)駐車場 = 有りorなし\n",
        "# (OK)周辺環境 = 小学校、大学\n",
        "# (そのままでOK)建物構造 = RC\n",
        "# (OK)契約期間 = 定期借家、契約年数\n",
        "\n",
        "# 特徴量を全部まとめていく"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qq3UURvBmY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a93260dc-ebe7-4903-fdfa-cfc216e507eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e12a3d662fdc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"エアコン付\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"バルコニー\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m       \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"バルコニー\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"フローリング\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"フローリング\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1942\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[0;31m# scalar value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0milocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_2d_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   2162\u001b[0m             \u001b[0;31m# set value into the column (first attempting to operate inplace, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;31m#  falling back to casting if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0;31m# This means we're expanding, with multiple columns, e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6459\u001b[0m         \"\"\"\n\u001b[1;32m   6460\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6463\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6318\u001b[0m         \u001b[0;31m# (note that this matches __getattr__, above).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_names_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6320\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6322\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mvalidate_all_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{type(self).__name__}.name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# (2)「所在地」について\n",
        "combined[\"地区\"] = \"0\"\n",
        "for row in range(max_row):\n",
        "  combined.loc[row,\"地区\"] = re.split(\"[都区]\", combined[\"所在地\"][row])[1]\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"所在地\"], axis=1)\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "# (3) 「アクセス」 = 「路線」「最寄り駅」「徒歩時間」に分ける\n",
        "combined[\"路線\"] = \"0\"\n",
        "combined[\"最寄り駅\"] = \"0\"\n",
        "# combined[\"徒歩時間\"] = \"0\" 無関係だと思う\n",
        "for row in range(max_row):\n",
        "  combined.loc[row,\"路線\"] = re.split(\"[\\t]\", combined[\"アクセス\"][row])[0]\n",
        "  combined.loc[row,\"最寄り駅\"] = re.split(\"[\\t]\", combined[\"アクセス\"][row])[1]\n",
        "  # combined.loc[row,\"徒歩時間\"] = re.split(\"[\\t]\", combined[\"アクセス\"][row])[2][-2:-1]\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"アクセス\"], axis=1)\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "# (4) 間取り = あまり関係ないように見えるので保留\n",
        "# (「納戸」を抹消する)\n",
        "# combined[\"間取り2\"] = \"0\"\n",
        "\n",
        "# for i in range(len(combined)):\n",
        "#   if(combined.loc[i,\"間取り\"][-4:])==\"(納戸)\":\n",
        "#     combined.loc[i,\"間取り2\"] = combined.loc[i,\"間取り\"][:-6]\n",
        "#   else:\n",
        "#     combined.loc[i,\"間取り2\"] = combined.loc[i,\"間取り\"]\n",
        "#---------------------------------------------------------------------------------\n",
        "# (5) 築年数(ヶ月に換算する)\n",
        "combined[\"築ヶ月\"] = \"0\"\n",
        "for i, val in enumerate(combined[\"築年数\"]):\n",
        "\n",
        "  # 「新築」表記を無くす\n",
        "  if(val == \"新築\"):\n",
        "    combined.loc[i,\"築ヶ月\"] = \"0\"\n",
        "    total = int(0)\n",
        "\n",
        "  else:\n",
        "    year = re.split(\"[年月ヶ]\",combined[\"築年数\"][i])[0]\n",
        "    month = re.split(\"[年月ヶ]\",combined[\"築年数\"][i])[1]\n",
        "    total = int(year) * 12 + int(month)\n",
        "  combined.loc[i,\"築ヶ月\"] = total\n",
        "\n",
        "# キャストする\n",
        "combined[\"築ヶ月\"] = combined[\"築ヶ月\"].astype(\"int32\")\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"築年数\"], axis=1)\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "# (7) 面積(数値に直す)\n",
        "combined[\"面積値\"] = \"0\"\n",
        "for i in range(max_row):\n",
        "  combined.loc[i, \"面積値\"] = combined[\"面積\"][i][:-2]\n",
        "\n",
        "# キャストする\n",
        "combined[\"面積値\"] = combined[\"面積値\"].astype(\"float32\")\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"面積\"], axis=1)\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "# (8) 所在階 = 階数に変換。欠損は2階を入れておく\n",
        "combined[\"所在階\"] = combined[\"所在階\"].fillna(\"2\")\n",
        "combined[\"階\"] = \"0\"\n",
        "for i in range(max_row):\n",
        "  combined.loc[i, \"階\"] = re.split(\"[階]\", combined[\"所在階\"][i])[0]\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"所在階\"], axis=1)\n",
        "# (9)「バス・トイレ」について\n",
        "combined[\"バス・トイレ\"] = combined[\"バス・トイレ\"].fillna(\"nodata\")\n",
        "combined[\"専用バス\"] = \"0\"\n",
        "combined[\"専用トイレ\"] = \"0\"\n",
        "combined[\"追焚機能\"] = \"0\"\n",
        "combined[\"浴室乾燥機\"] = \"0\"\n",
        "combined[\"温水洗浄便座\"] = \"0\"\n",
        "combined[\"洗面台独立\"] = \"0\"\n",
        "for row in range(max_row):\n",
        "  tmp = re.split(\"[\\t]\", combined[\"バス・トイレ\"][row])\n",
        "\n",
        "  # 空要素を削除\n",
        "  tmp = [i for i in tmp if i != \"\"]\n",
        "\n",
        "  # フラグ\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"専用バス\":\n",
        "      combined.loc[row,\"専用バス\"] = \"1\"\n",
        "    if term == \"専用トイレ\":\n",
        "      combined.loc[row,\"専用トイレ\"] = \"1\"\n",
        "    if term == \"追焚機能\":\n",
        "      combined.loc[row,\"追焚機能\"] = \"1\"\n",
        "    if term == \"浴室乾燥機\":\n",
        "      combined.loc[row,\"浴室乾燥機\"] = \"1\"\n",
        "    if term == \"温水洗浄便座\":\n",
        "      combined.loc[row,\"温水洗浄便座\"] = \"1\"\n",
        "    if term == \"洗面台独立\":\n",
        "      combined.loc[row,\"洗面台独立\"] = \"1\"\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"バス・トイレ\"], axis=1)\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "# (10)「キッチン」について\n",
        "combined[\"キッチン\"] = combined[\"キッチン\"].fillna(\"nodata\")\n",
        "\n",
        "# 新規カラム\n",
        "combined[\"ガスコンロ\"] = \"0\"\n",
        "combined[\"コンロ4口以上\"] = \"0\"\n",
        "combined[\"給湯\"] = \"0\"\n",
        "combined[\"システムキッチン\"] = \"0\"\n",
        "combined[\"カウンターキッチン\"] = \"0\"\n",
        "combined[\"電気コンロ\"] = \"0\"\n",
        "\n",
        "# フラグ処理\n",
        "for row in range(max_row):\n",
        "  tmp = re.split(\"[\\t]\", combined[\"キッチン\"][row])\n",
        "\n",
        "  # 空要素を削除\n",
        "  tmp = [i for i in tmp if i != \"\"]\n",
        "\n",
        "  # フラグ\n",
        "  for i, term in enumerate(tmp):\n",
        "\n",
        "    if term == \"ガスコンロ\":\n",
        "      combined.loc[row,\"ガスコンロ\"] = \"1\"\n",
        "    if term == \"コンロ4口以上\":\n",
        "      combined.loc[row,\"コンロ4口以上\"] = \"1\"\n",
        "    if term == \"給湯\":\n",
        "      combined.loc[row,\"給湯\"] = \"1\"\n",
        "    if term == \"システムキッチン\":\n",
        "      combined.loc[row,\"システムキッチン\"] = \"1\"\n",
        "    if term == \"カウンターキッチン\":\n",
        "      combined.loc[row,\"カウンターキッチン\"] = \"1\"\n",
        "    if term == \"IHコンロ\":\n",
        "      combined.loc[row,\"IHコンロ\"] = \"1\"\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"キッチン\"], axis=1)\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "# (11)「放送・通信」について\n",
        "combined[\"放送・通信\"] = combined[\"放送・通信\"].fillna(\"nodata\")\n",
        "\n",
        "# 新規カラム\n",
        "combined[\"インターネット対応\"] = \"0\"\n",
        "combined[\"光ファイバー\"] = \"0\"\n",
        "combined[\"CATV\"] = \"0\"\n",
        "combined[\"CSアンテナ\"] = \"0\"\n",
        "combined[\"BSアンテナ\"] = \"0\"\n",
        "\n",
        "# フラグ処理\n",
        "for row in range(max_row):\n",
        "  tmp = re.split(\"[\\t]\", combined[\"放送・通信\"][row])\n",
        "\n",
        "  # 空要素を削除\n",
        "  tmp = [i for i in tmp if i != \"\"]\n",
        "\n",
        "  # フラグ\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"インターネット対応\":\n",
        "      combined.loc[row,\"インターネット対応\"] = \"1\"\n",
        "    if term == \"光ファイバー\":\n",
        "      combined.loc[row,\"光ファイバー\"] = \"1\"\n",
        "    if term == \"CATV\":\n",
        "      combined.loc[row,\"CATV\"] = \"1\"\n",
        "    if term == \"CSアンテナ\":\n",
        "      combined.loc[row,\"CSアンテナ\"] = \"1\"\n",
        "    if term == \"BSアンテナ\":\n",
        "      combined.loc[row,\"BSアンテナ\"] = \"1\"\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"放送・通信\"], axis=1)\n",
        "# (12)「室内設備」について\n",
        "combined[\"室内設備\"] = combined[\"室内設備\"].fillna(\"nodata\")\n",
        "\n",
        "# 新規カラム\n",
        "combined[\"エアコン付\"] = \"0\"\n",
        "combined[\"バルコニー\"] = \"0\"\n",
        "combined[\"フローリング\"] = \"0\"\n",
        "combined[\"室内洗濯機置場\"] = \"0\"\n",
        "combined[\"敷地内ゴミ置き場\"] = \"0\"\n",
        "combined[\"エレベーター\"] = \"0\"\n",
        "combined[\"都市ガス\"] = \"0\"\n",
        "combined[\"ロフト付き\"] = \"0\"\n",
        "combined[\"オール電化\"] = \"0\"\n",
        "combined[\"床暖房\"] = \"0\"\n",
        "combined[\"シューズボックス\"] = \"0\"\n",
        "combined[\"24時間換気システム\"] = \"0\"\n",
        "combined[\"タイル張り\"] = \"0\"\n",
        "combined[\"2面採光\"] = \"0\"\n",
        "combined[\"下水\"] = \"0\"\n",
        "combined[\"公営水道\"] = \"0\"\n",
        "combined[\"冷房\"] = \"0\"\n",
        "\n",
        "# フラグ処理\n",
        "for row in range(max_row):\n",
        "  tmp = re.split(\"[／\\t]\", combined[\"室内設備\"][row])\n",
        "\n",
        "  # 空要素を削除\n",
        "  tmp = [i for i in tmp if i != \"\"]\n",
        "\n",
        "  # フラグ\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"エアコン付\":\n",
        "      combined.loc[row,\"エアコン付\"] = \"1\"\n",
        "    if term == \"バルコニー\":\n",
        "      combined.loc[row,\"バルコニー\"] = \"1\"\n",
        "    if term == \"フローリング\":\n",
        "      combined.loc[row,\"フローリング\"] = \"1\"\n",
        "    if term == \"室内洗濯機置場\":\n",
        "      combined.loc[row,\"室内洗濯機置場\"] = \"1\"\n",
        "    if term == \"敷地内ゴミ置き場\":\n",
        "      combined.loc[row,\"敷地内ゴミ置き場\"] = \"1\"\n",
        "    if term == \"エレベーター\":\n",
        "      combined.loc[row,\"エレベーター\"] = \"1\"\n",
        "    if term == \"都市ガス\":\n",
        "      combined.loc[row,\"都市ガス\"] = \"1\"\n",
        "    if term == \"ロフト付き\":\n",
        "      combined.loc[row,\"ロフト付き\"] = \"1\"\n",
        "    if term == \"オール電化\":\n",
        "      combined.loc[row,\"オール電化\"] = \"1\"\n",
        "    if term == \"床暖房\":\n",
        "      combined.loc[row,\"床暖房\"] = \"1\"\n",
        "    if term == \"シューズボックス\":\n",
        "      combined.loc[row,\"シューズボックス\"] = \"1\"\n",
        "    if term == \"24時間換気システム\":\n",
        "      combined.loc[row,\"24時間換気システム\"] = \"1\"\n",
        "    if term == \"タイル張り\":\n",
        "      combined.loc[row,\"タイル張り\"] = \"1\"\n",
        "    if term == \"2面採光\":\n",
        "      combined.loc[row,\"2面採光\"] = \"1\"\n",
        "    if term == \"下水\":\n",
        "      combined.loc[row,\"下水\"] = \"1\"\n",
        "    if term == \"公営水道\":\n",
        "      combined.loc[row,\"公営水道\"] = \"1\"\n",
        "    if term == \"冷房\":\n",
        "      combined.loc[row,\"冷房\"] = \"1\"\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"室内設備\"], axis=1)\n",
        "# (13)「駐車場」について\n",
        "combined[\"駐車場\"] = combined[\"駐車場\"].fillna(\"nodata\")\n",
        "\n",
        "# 新規カラム\n",
        "combined[\"空有\"] = \"0\"\n",
        "combined[\"バイク置き場\"] = \"0\"\n",
        "\n",
        "# フラグ処理\n",
        "for row in range(max_row):\n",
        "  tmp = re.split(\"[\\t]\", combined[\"駐車場\"][row])\n",
        "\n",
        "  # 空要素を削除\n",
        "  tmp = [i for i in tmp if i != \"\"]\n",
        "\n",
        "  # フラグ\n",
        "  for i, term in enumerate(tmp):\n",
        "\n",
        "    if term == \"空有\":\n",
        "      combined.loc[row,\"空有\"] = \"1\"\n",
        "\n",
        "    if term == \"バイク置き場\":\n",
        "      combined.loc[row,\"バイク置き場\"] = \"1\"\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"駐車場\"], axis=1)\n",
        "# (14)「周辺環境」について\n",
        "combined[\"周辺環境\"] = combined[\"周辺環境\"].fillna(\"nodata\")\n",
        "\n",
        "# 新規カラム\n",
        "combined[\"小学校\"] = 2000\n",
        "combined[\"大学\"] = 2000\n",
        "combined[\"公園\"] = 2000\n",
        "combined[\"飲食店\"] = 2000\n",
        "combined[\"スーパー\"] = 2000\n",
        "combined[\"ドラッグストア\"] = 2000\n",
        "combined[\"郵便局\"] = 2000\n",
        "\n",
        "# フラグ処理\n",
        "for row in range(max_row):\n",
        "  tmp = re.split(\"[ \\t]\", combined[\"周辺環境\"][row])\n",
        "\n",
        "  # 空要素を削除\n",
        "  tmp = [i for i in tmp if i != \"\"]\n",
        "\n",
        "  # フラグ\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"【小学校】\":\n",
        "      combined.loc[row,\"小学校\"] = int(tmp[i+1] [:-1])\n",
        "      break\n",
        "\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"【大学】\":\n",
        "      combined.loc[row,\"大学\"] = int(tmp[i+1] [:-1])\n",
        "      break\n",
        "\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"【公園】\":\n",
        "      combined.loc[row,\"公園\"] = int(tmp[i+1] [:-1])\n",
        "      break\n",
        "\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"【飲食店】\":\n",
        "      combined.loc[row,\"飲食店\"] = int(tmp[i+1] [:-1])\n",
        "      break\n",
        "\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"【スーパー】\":\n",
        "      combined.loc[row,\"スーパー\"] = int(tmp[i+1] [:-1])\n",
        "      break\n",
        "\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"【ドラッグストア】\":\n",
        "      combined.loc[row,\"ドラッグストア\"] = int(tmp[i+1] [:-1])\n",
        "      break\n",
        "\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"【郵便局】\":\n",
        "      combined.loc[row,\"郵便局\"] = int(tmp[i+1] [:-1])\n",
        "      break\n",
        "\n",
        "# 元のカラムを消去\n",
        "combined = combined.drop([\"周辺環境\"], axis=1)\n",
        "# 「契約期間」について\n",
        "combined[\"契約期間\"] = combined[\"契約期間\"].fillna(\"nodata\")\n",
        "combined[\"定期借家\"] = \"0\"\n",
        "combined[\"契約年数\"] = \"0\"\n",
        "for row in range(max_row):\n",
        "  tmp = re.split(\"[\\t]\", combined[\"契約期間\"][row])\n",
        "\n",
        "  # 空要素を削除\n",
        "  tmp = [i for i in tmp if i != \"\"]\n",
        "\n",
        "  # 定期借家フラグ\n",
        "  for i, term in enumerate(tmp):\n",
        "    if term == \"定期借家\":\n",
        "      combined.loc[row,\"定期借家\"] = \"1\"\n",
        "\n",
        "  # 契約年数\n",
        "  combined.loc[row,\"契約年数\"] = tmp[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DGbfLYPo_ND"
      },
      "outputs": [],
      "source": [
        "# 取り除く変数\n",
        "RMV = [\"id\", \"賃料\"]\n",
        "FEATURES = [c for c in combined.columns if not c in RMV]\n",
        "\n",
        "# カテゴリ変数の分類\n",
        "CATS = []\n",
        "for c in FEATURES:\n",
        "  if combined[c].dtype == \"object\":\n",
        "    CATS.append(c)\n",
        "    combined[c] = combined[c].fillna(\"nodata\")\n",
        "    # test[c] = test[c].fillna(\"NAN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1ICi2ckp1LU"
      },
      "outputs": [],
      "source": [
        "# 特徴量の整理\n",
        "for c in FEATURES:\n",
        "\n",
        "  # カテゴリ変数の場合はラベルエンコード\n",
        "  for c in CATS:\n",
        "    combined[c],_ = combined[c].factorize()\n",
        "\n",
        "    combined[c] -= combined[c].min() # 最小値で引く\n",
        "    combined[c] = combined[c].astype(\"int32\")\n",
        "\n",
        "  # 数値の場合はメモリを減らす\n",
        "  else:\n",
        "    if combined[c].dtype == \"float64\":\n",
        "      combined[c] = combined[c].astype(\"float32\")\n",
        "    if combined[c].dtype == \"int64\":\n",
        "      combined[c] = combined[c].astype(\"int32\")\n",
        "\n",
        "# 結合を戻す\n",
        "train = combined.iloc[:len(train)].copy()\n",
        "test = combined.iloc[len(train):].reset_index(drop=True).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEXGOvEcw-sF"
      },
      "outputs": [],
      "source": [
        "!pip install optuna lightgbm scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv5OKdxxoLKw",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "  lgbm_params = {\n",
        "      'objective': 'regression',\n",
        "      \"device\": \"cuda\",\n",
        "      'metric': 'rmse',\n",
        "      'verbosity': 100,\n",
        "      'num_boost_round': 6000,\n",
        "      'boosting_type': 'gbdt',\n",
        "      'learning_rate': 0.05,            # 学習率\n",
        "      'num_leaves': 31,                 # 葉の数\n",
        "      'max_depth': -1,                  # 木の深さ（デフォルトは無制限）\n",
        "      'feature_fraction': 0.9,          # 学習に使用する特徴量の割合\n",
        "      'bagging_fraction': 0.8,          # サンプリングの割合\n",
        "      'bagging_freq': 5,                # バギングの頻度（1回ごと、あるいは5回ごと）\n",
        "      'verbose': -1                     # ログ出力の制御\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "FOLDS = 5 # 分割数\n",
        "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "oof_lgb = np.zeros(len(train))\n",
        "pred_lgb = np.zeros(len(test))\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
        "\n",
        "  print(\"#\"*25)\n",
        "  print(f\"### Fold {i+1}\")\n",
        "  print(\"#\"*25)\n",
        "\n",
        "  # インデックスに割り振る\n",
        "\n",
        "  x_train = train.loc[train_index, FEATURES].copy()\n",
        "  y_train = train.loc[train_index, \"賃料\"]\n",
        "  x_valid = train.loc[test_index, FEATURES].copy()\n",
        "  y_valid = train.loc[test_index, \"賃料\"]\n",
        "  x_test = test[FEATURES].copy()\n",
        "\n",
        "  # データセット作成\n",
        "  lgb_train = lgb.Dataset(x_train, y_train)\n",
        "  lgb_eval = lgb.Dataset(x_valid, y_valid, reference = lgb_train)\n",
        "\n",
        "  # 学習\n",
        "  model_lgb = lgb.train(lgbm_params,\n",
        "                        lgb_train,\n",
        "                        valid_sets = lgb_eval,\n",
        "                        callbacks = [\n",
        "                            lgb.early_stopping(stopping_rounds=100, verbose=True),\n",
        "                            # lgb.log_evaluation(100),\n",
        "                            ])\n",
        "\n",
        "\n",
        "  y_pred = model_lgb.predict(x_valid, num_iteration = model_lgb.best_iteration)\n",
        "\n",
        "  oof_lgb[test_index] = model_lgb.predict(x_valid)\n",
        "  pred_lgb += model_lgb.predict(x_test)\n",
        "\n",
        "# 平均評価\n",
        "pred_lgb /= FOLDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrdvQA4HIucS",
        "outputId": "c67d38ff-cc94-436b-8c28-ceaf3f590b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#########################\n",
            "### Fold 1\n",
            "#########################\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.625800\n",
            "[LightGBM] [Info] Total Bins 2869\n",
            "[LightGBM] [Info] Number of data points in the train set: 25176, number of used features: 52\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Adding init score = 118394.632904\n",
            "[LightGBM] [Debug] Adding init score = 118394.632904\n",
            "[LightGBM] [Info] Start training from score 118394.632904\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20099 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19936 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20267 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20275 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20029 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20213 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20232 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20255 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20150 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20083 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20179 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20065 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20069 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20156 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20125 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20216 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20092 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20009 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20143 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20165 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20042 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20075 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20110 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20187 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20175 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20210 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20103 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20167 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20041 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20224 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20264 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20035 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20208 data to train\n",
            "Early stopping, best iteration is:\n",
            "[375]\tvalid_0's rmse: 21098.9\n",
            "#########################\n",
            "### Fold 2\n",
            "#########################\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.625914\n",
            "[LightGBM] [Info] Total Bins 2877\n",
            "[LightGBM] [Info] Number of data points in the train set: 25176, number of used features: 52\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Adding init score = 118247.160867\n",
            "[LightGBM] [Debug] Adding init score = 118247.160867\n",
            "[LightGBM] [Info] Start training from score 118247.160867\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20099 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19936 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20267 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20275 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20029 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20213 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20232 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20255 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20150 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20083 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20179 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20065 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20069 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20156 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20125 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20216 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20092 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20009 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20143 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20165 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20042 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20075 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20110 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20187 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20175 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20210 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20103 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20167 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20041 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20224 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20264 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20035 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20208 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20250 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20197 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20005 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20025 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20112 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20082 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20106 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20109 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20026 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20078 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20188 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20199 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20189 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20147 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20273 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20097 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20227 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20046 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20050 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20152 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20067 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20293 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20024 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20207 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20121 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20162 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20155 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20139 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20129 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20188 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20139 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20148 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20102 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20095 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20182 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20073 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20119 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20085 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20094 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20132 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "Early stopping, best iteration is:\n",
            "[739]\tvalid_0's rmse: 24594.2\n",
            "#########################\n",
            "### Fold 3\n",
            "#########################\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.625424\n",
            "[LightGBM] [Info] Total Bins 2867\n",
            "[LightGBM] [Info] Number of data points in the train set: 25176, number of used features: 52\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Adding init score = 118558.397521\n",
            "[LightGBM] [Debug] Adding init score = 118558.397521\n",
            "[LightGBM] [Info] Start training from score 118558.397521\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20099 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19936 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20267 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20275 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20029 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20213 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20232 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20255 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20150 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20083 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20179 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20065 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20069 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20156 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20125 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20216 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20092 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20009 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20143 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20165 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20042 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20075 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20110 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20187 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20175 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20210 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20103 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20167 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20041 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20224 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20264 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20035 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20208 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20250 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20197 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20005 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20025 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20112 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20082 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20106 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20109 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20026 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20078 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20188 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20199 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20189 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20147 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20273 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20097 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20227 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20046 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20050 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20152 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20067 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20293 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20024 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20207 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20121 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20162 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20155 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20139 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20129 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20188 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20139 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20148 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20102 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20095 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20182 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20073 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20119 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20085 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20094 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20132 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20205 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20033 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20146 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20103 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20131 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20071 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20114 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20148 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20095 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20035 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20180 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20191 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19958 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20183 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20229 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20133 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20198 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20079 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20165 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20272 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20129 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20131 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20045 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20121 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20107 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20187 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "Early stopping, best iteration is:\n",
            "[901]\tvalid_0's rmse: 18946.3\n",
            "#########################\n",
            "### Fold 4\n",
            "#########################\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.625751\n",
            "[LightGBM] [Info] Total Bins 2875\n",
            "[LightGBM] [Info] Number of data points in the train set: 25176, number of used features: 52\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Adding init score = 118256.291150\n",
            "[LightGBM] [Debug] Adding init score = 118256.291150\n",
            "[LightGBM] [Info] Start training from score 118256.291150\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20099 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19936 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20267 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20275 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20029 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20213 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20232 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20255 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20150 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20083 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20179 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20065 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20069 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20156 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20125 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20216 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20092 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20009 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20143 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20165 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20042 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20075 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20110 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20187 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20175 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20210 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20103 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20167 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20041 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20224 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20264 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20035 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20208 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20250 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20197 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20005 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20025 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20112 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20082 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20106 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20109 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20026 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20078 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20188 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20199 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20189 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20147 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20273 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20097 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20227 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20046 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20050 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20152 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20067 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20293 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20024 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20207 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20121 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20162 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20155 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20139 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20129 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20188 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20139 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20148 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20102 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20095 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20182 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20073 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20119 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20085 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20094 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20132 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20205 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20033 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20146 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20103 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20131 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20071 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20114 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20148 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20095 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20035 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20180 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20191 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19958 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20183 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20229 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20133 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20198 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20079 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20165 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20272 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20129 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20131 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20045 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20121 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20107 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20187 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20239 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20251 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20123 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20151 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20190 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19981 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20228 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20175 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20256 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20174 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20156 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20169 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20127 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20200 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20084 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20190 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20094 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20143 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20222 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20208 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20120 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20137 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20078 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20146 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20080 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20149 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20197 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20226 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20219 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20210 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20242 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20148 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20210 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20069 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20261 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20162 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20119 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20028 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20075 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20129 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20213 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20150 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20227 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20206 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20226 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20186 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20198 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20212 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20181 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20050 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20158 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19980 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20044 data to train\n",
            "Early stopping, best iteration is:\n",
            "[1351]\tvalid_0's rmse: 18324.5\n",
            "#########################\n",
            "### Fold 5\n",
            "#########################\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.625515\n",
            "[LightGBM] [Info] Total Bins 2879\n",
            "[LightGBM] [Info] Number of data points in the train set: 25176, number of used features: 52\n",
            "[LightGBM] [Warning] verbosity is set=100, verbose=-1 will be ignored. Current value: verbosity=100\n",
            "[LightGBM] [Debug] Adding init score = 117995.049650\n",
            "[LightGBM] [Debug] Adding init score = 117995.049650\n",
            "[LightGBM] [Info] Start training from score 117995.049650\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Debug] Re-bagging, using 20176 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20099 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 19936 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20267 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20275 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20029 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20135 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20141 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20161 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20213 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20192 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20232 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20255 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20150 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20083 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20179 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20144 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20145 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20065 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20069 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20177 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20156 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20125 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20113 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20216 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20092 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20009 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20142 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20143 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20165 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20173 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20164 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20160 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20042 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20154 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20178 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20075 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20110 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20068 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20187 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20175 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20210 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20103 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20167 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20041 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20185 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20209 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20172 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20118 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20168 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20224 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20264 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20140 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20211 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20171 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20203 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20035 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20231 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20157 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20053 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20134 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20208 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20250 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20197 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20005 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20218 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20086 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20025 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20112 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20082 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20106 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20093 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20109 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20223 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20026 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20078 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20188 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20199 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20130 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20136 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20128 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20091 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20189 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20147 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20116 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20221 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20273 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20090 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20097 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20227 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20046 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20050 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20072 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20089 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20152 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20087 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20111 data to train\n",
            "[LightGBM] [Debug] Re-bagging, using 20195 data to train\n",
            "Early stopping, best iteration is:\n",
            "[570]\tvalid_0's rmse: 28532.3\n",
            "CPU times: user 2min 41s, sys: 194 ms, total: 2min 41s\n",
            "Wall time: 33.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6Y0DHVgkc-v",
        "outputId": "321f1f88-02e7-4db6-a579-c3b8112690b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall CV for LightGBM =  22622.46377226914\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 検証用スコアデータの算出\n",
        "y_true = train[\"賃料\"].tolist()\n",
        "m = np.sqrt(mean_squared_error(y_true, oof_lgb.tolist()))\n",
        "print(f\"\\nOverall CV for LightGBM = \",m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AMQ3jfc09go"
      },
      "outputs": [],
      "source": [
        "submit[\"賃料\"] = pd.DataFrame(pred_lgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqGi3eF5z1xt"
      },
      "outputs": [],
      "source": [
        "submit.to_csv(\"submission.csv\", header=False, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9QPP_hDp9pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY3_m0lwmk6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "22c8f2e7-af61-4c31-b456-ea3b279c5664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2025-03-15 23:23:57,517]\u001b[0m A new study created in memory with name: no-name-f9522470-0bec-48ee-a453-3fea0617c70c\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Fold 1\n",
            "### Fold 2\n",
            "### Fold 3\n",
            "### Fold 4\n",
            "### Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2025-03-15 23:24:20,769]\u001b[0m Trial 0 finished with value: 26689.29609199935 and parameters: {'min_data_in_leaf': 28}. Best is trial 0 with value: 26689.29609199935.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Fold 1\n",
            "### Fold 2\n",
            "### Fold 3\n",
            "### Fold 4\n",
            "### Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2025-03-15 23:24:41,609]\u001b[0m Trial 1 finished with value: 25057.236880700406 and parameters: {'min_data_in_leaf': 18}. Best is trial 1 with value: 25057.236880700406.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Fold 1\n",
            "### Fold 2\n",
            "### Fold 3\n",
            "### Fold 4\n",
            "### Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2025-03-15 23:25:02,977]\u001b[0m Trial 2 finished with value: 28582.716812684048 and parameters: {'min_data_in_leaf': 61}. Best is trial 1 with value: 25057.236880700406.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Fold 1\n",
            "### Fold 2\n",
            "### Fold 3\n",
            "### Fold 4\n",
            "### Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2025-03-15 23:25:23,196]\u001b[0m Trial 3 finished with value: 30744.405816473438 and parameters: {'min_data_in_leaf': 88}. Best is trial 1 with value: 25057.236880700406.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Fold 1\n",
            "### Fold 2\n",
            "### Fold 3\n",
            "### Fold 4\n",
            "### Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2025-03-15 23:25:42,034]\u001b[0m Trial 4 finished with value: 30834.02979418597 and parameters: {'min_data_in_leaf': 91}. Best is trial 1 with value: 25057.236880700406.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trial: {'min_data_in_leaf': 18}\n",
            "Best trial: {'min_data_in_leaf': 18}\n"
          ]
        }
      ],
      "source": [
        "# %%time\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold # K分割\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import xgboost\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# lambda_l1 (L1正則化項の係数)\n",
        "# lambda_l2 (L2正則化項の係数)\n",
        "# num_leaves (1本の木の最大葉枚数)\n",
        "# feature_fraction (各決定木においてランダムに抽出される列の割合)\n",
        "# bagging_fraction (各決定木においてランダムに抽出される標本の割合)\n",
        "# bagging_freq (ここで指定したイテレーション毎にバギング実施)\n",
        "# min_child_sample (1枚の葉に含まれる最小データ数)\n",
        "\n",
        "# チューニング開始\n",
        "def objective(trial):\n",
        "\n",
        "  # ハイパーパラメータの探索空間を定義\n",
        "  param = {\n",
        "      'objective': 'regression',\n",
        "      \"device\": \"cuda\",\n",
        "      'metric': 'rmse',\n",
        "      'verbosity': -1,\n",
        "      'boosting_type': 'gbdt',\n",
        "      'learning_rate': 0.04492708210966157,\n",
        "      # 'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.1), # 10回\n",
        "      'feature_fraction': 0.9103130112582689,\n",
        "      # 'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0), # 7回\n",
        "      'num_leaves': 224, # 20回\n",
        "      # 'num_leaves': trial.suggest_int('num_leaves', 2, 256), # 20回\n",
        "      'bagging_fraction': 0.9568588888194215,\n",
        "      'bagging_freq': 1,\n",
        "      # 'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0), # 10 回\n",
        "      # 'bagging_freq': trial.suggest_float('bagging_freq', 1, 7), # 10回\n",
        "      'feature_fraction': 0.9591216929519641,\n",
        "      # 'feature_fraction': trial.suggest_float('feature_fraction', 1, 7), # 7回\n",
        "      'lambda_l1': 0.0709541557442255,\n",
        "      'lambda_l2': 8.094433861762296e-07,\n",
        "      # 'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0), 20回\n",
        "      # 'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
        "      'min_data_in_leaf': 18,\n",
        "      # 'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # 10回\n",
        "      }\n",
        "\n",
        "  FOLDS = 5 # 分割数\n",
        "  kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "  oof_lgb = np.zeros(len(train))\n",
        "  # pred_lgb = np.zeros(len(test))\n",
        "\n",
        "  for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
        "\n",
        "    # print(\"#\"*25)\n",
        "    print(f\"### Fold {i+1}\")\n",
        "    # print(\"#\"*25)\n",
        "\n",
        "    # インデックスに割り振る\n",
        "    x_train = train.loc[train_index, FEATURES].copy()\n",
        "    y_train = train.loc[train_index, \"賃料\"]\n",
        "    x_valid = train.loc[test_index, FEATURES].copy()\n",
        "    y_valid = train.loc[test_index, \"賃料\"]\n",
        "    x_test = test[FEATURES].copy()\n",
        "\n",
        "    # データセット作成\n",
        "    lgb_train = lgb.Dataset(x_train, y_train)\n",
        "    lgb_eval = lgb.Dataset(x_valid, y_valid, reference = lgb_train)\n",
        "\n",
        "    # 学習\n",
        "    model_lgb = lgb.train(param,\n",
        "                          lgb_train,\n",
        "                          valid_sets = lgb_eval,\n",
        "                          callbacks = [\n",
        "                              lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
        "                              ])\n",
        "\n",
        "    y_pred = model_lgb.predict(x_valid, num_iteration = model_lgb.best_iteration)\n",
        "\n",
        "    oof_lgb[test_index] = model_lgb.predict(x_valid)\n",
        "    # pred_lgb += model_lgb.predict(x_test)\n",
        "\n",
        "  # 平均評価\n",
        "  # oof_lgb /= FOLDS\n",
        "  # pred_lgb /= FOLDS\n",
        "\n",
        "  # 検証用スコアデータの算出\n",
        "  y_true = train[\"賃料\"].tolist()\n",
        "  m = np.sqrt(mean_squared_error(y_true, oof_lgb.tolist()))\n",
        "  # print(f\"\\nOverall CV for LightGBM = \",m)\n",
        "  return m\n",
        "\n",
        "# Optunaで最適化を実行\n",
        "study = optuna.create_study(direction='minimize')  # RMSEを最小化する方向で最適化\n",
        "\n",
        "study.optimize(objective, n_trials=5)\n",
        "print(f'trial: {study.best_trial.params}')\n",
        "print(f'Best trial: {study.best_trial.params}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ベースラインを作成する\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold # K分割\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import xgboost\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "\n",
        "\n",
        "# LGBMパラメータ\n",
        "# lgbm_params = {\n",
        "#     \"objective\": \"regression\",\n",
        "#     # \"device\": \"gpu\",\n",
        "#     \"device\": \"cuda\",\n",
        "#     'verbose': -1,\n",
        "#     \"boosting\": \"gbdt\",\n",
        "#     'metric': 'rmse',\n",
        "#     'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "#     # 'min_child_samples': 32,\n",
        "#     # 'max_depth': 8,\n",
        "#     # 'max_bin': 128,\n",
        "#     # \"colsample_bytree\": 0.4,\n",
        "#     # \"subsample\": 0.9,\n",
        "#     # 'learning_rate': 0.1,\n",
        "#     # 'extra_trees': True,\n",
        "#     # 'reg_lambda': 8.0,\n",
        "#     # 'reg_alpha': 0.1,\n",
        "#     # 'num_leaves': 64,\n",
        "#     \"seed\": 1234,\n",
        "#     # \"is_enable_sparse\": \"False\",\n",
        "# }\n",
        "\n",
        "\n",
        "# OptunaでLightGBMのハイパーパラメータを最適化する関数\n",
        "def objective(trial):\n",
        "    # ハイパーパラメータの探索空間を定義\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        \"device\": \"cuda\",\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0), # 7回\n",
        "        # 'num_leaves': trial.suggest_int('num_leaves', 2, 256), # 20回\n",
        "        # 'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "        # 'bagging_freq': trial.suggest_uniform('bagging_freq', 1, 7),\n",
        "        # 'feature_fraction': trial.suggest_uniform('feature_fraction', 1, 7), # 2回目\n",
        "        # 'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
        "        # 'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
        "        # 'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
        "        # 'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.1),\n",
        "        # 'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
        "        # 'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "    }\n",
        "\n",
        "    # 学習\n",
        "    model_lgb = lgb.train(param,\n",
        "                          lgb_train,\n",
        "                          valid_sets = lgb_eval,\n",
        "                          callbacks = [\n",
        "                              lgb.early_stopping(stopping_rounds=100, verbose=True),\n",
        "                              lgb.log_evaluation(100),])\n",
        "\n",
        "\n",
        "    y_pred = model_lgb.predict(x_valid, num_iteration = model_lgb.best_iteration)\n",
        "\n",
        "    oof_lgb[test_index] = model_lgb.predict(x_valid)\n",
        "\n",
        "    # 検証データで予測\n",
        "    y_pred = model.predict(X_valid)\n",
        "\n",
        "    # RMSE (Root Mean Squared Error) を手動で計算\n",
        "    mse = mean_squared_error(y_valid, y_pred)\n",
        "    rmse = np.sqrt(mse)  # MSEの平方根を取ってRMSEを計算\n",
        "\n",
        "    return rmse\n",
        "\n",
        "# Optunaで最適化を実行\n",
        "study = optuna.create_study(direction='minimize')  # RMSEを最小化する方向で最適化\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "euvY0-rzp9uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "FOLDS = 5 # 分割数\n",
        "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "oof_lgb = np.zeros(len(train))\n",
        "pred_lgb = np.zeros(len(test))\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
        "\n",
        "  print(\"#\"*25)\n",
        "  print(f\"### Fold {i+1}\")\n",
        "  print(\"#\"*25)\n",
        "\n",
        "  # インデックスに割り振る\n",
        "\n",
        "  x_train = train.loc[train_index, FEATURES].copy()\n",
        "  y_train = train.loc[train_index, \"賃料\"]\n",
        "  x_valid = train.loc[test_index, FEATURES].copy()\n",
        "  y_valid = train.loc[test_index, \"賃料\"]\n",
        "  x_test = test[FEATURES].copy()\n",
        "\n",
        "  # データセット作成\n",
        "  lgb_train = lgb.Dataset(x_train, y_train)\n",
        "  lgb_eval = lgb.Dataset(x_valid, y_valid, reference = lgb_train)\n",
        "\n",
        "  # 学習\n",
        "  model_lgb = lgb.train(lgbm_params,\n",
        "                        lgb_train,\n",
        "                        valid_sets = lgb_eval,\n",
        "                        callbacks = [\n",
        "                            lgb.early_stopping(stopping_rounds=100, verbose=True),\n",
        "                            lgb.log_evaluation(100),])\n",
        "\n",
        "\n",
        "  y_pred = model_lgb.predict(x_valid, num_iteration = model_lgb.best_iteration)\n",
        "\n",
        "  oof_lgb[test_index] = model_lgb.predict(x_valid)\n",
        "  pred_lgb += model_lgb.predict(x_test)\n",
        "\n",
        "# 平均評価\n",
        "pred_lgb /= FOLDS"
      ],
      "metadata": {
        "id": "BmLzv4tOp9zW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 10381525,
          "sourceId": 70942,
          "sourceType": "competition"
        },
        {
          "sourceId": 211322530,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 217304343,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 219607918,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 224040652,
          "sourceType": "kernelVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}